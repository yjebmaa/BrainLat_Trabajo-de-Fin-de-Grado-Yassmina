# -*- coding: utf-8 -*-
"""02_BrainLat_modelosConT1MRI.ipynb

Automatically generated by Colab.

# 1. LECTURA DE DATOS, DESCARGA Y VISUALIZACIÓN.
"""

# Commented out IPython magic to ensure Python compatibility.
# %pip install --upgrade pysftp synapseclient python-dotenv
# %pip install --upgrade synapseclient
!pip install nibabel matplotlib numpy
!pip install pyradiomics SimpleITK
!pip uninstall -y tensorflow
!pip install tensorflow==2.12.0
!pip install monai
!pip install torch torchvision
!git clone https://github.com/Tencent/MedicalNet.git
!cd MedicalNet
!pip install -q monai torchio

import os
import pandas as pd
from dotenv import load_dotenv
import synapseclient
import synapseutils
import nibabel as nib
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
import tensorflow as tf
from scipy.ndimage import zoom

# Leemos el CSV con los pacientes
filtered_df = pd.read_csv("directorio_censurado/BrainLat_Imputado3.csv", delimiter=";")
patient_ids = filtered_df["MRI_ID"].unique()

import os
import pandas as pd
from dotenv import load_dotenv
import synapseclient
import synapseutils

load_dotenv()
# Iniciamos sesión en Synapse
SYNAPSE_TOKEN = "token_censurado"
syn = synapseclient.Synapse()
syn.login(authToken=SYNAPSE_TOKEN)

# Leemos el CSV con los pacientes
filtered_df = pd.read_csv("directorio_censurado/BrainLat_Imputado3.csv", delimiter=";")
patient_ids = filtered_df["MRI_ID"].unique()

# Obtenemos la lista de archivos disponibles en Synapse
entity = syn.get('syn51549340', downloadFile=False)
file_list = list(synapseutils.walk(syn, entity.id))

# Descargamos solo los archivos que coincidan con los pacientes en MRI_ID
for dirpath, dirnames, filenames in file_list:
  for dir in dirpath:
    for filename in filenames:
      for patient_id in patient_ids:
        if patient_id in dir and "BrainLat_dataset_NewIDs" in dir:
          file_path = os.path.join('/Volumes/T7/BrainLat', dir[17:])
          try:
            syn.get(filename[1], downloadLocation=file_path)
            print(f"✅ Descargado: {filename[0]}")
          except Exception as e:
            print(f"❌ Error con {filename[0]}: {e}")

import nibabel as nib
import numpy as np
import matplotlib.pyplot as plt

# Ruta de la imagen
nii_path = "/Volumes/T7/BrainLat/MRI data/BrainLat_dataset_NewIDs/sub-COB086/anat/sub-COB086_T1w.nii.gz"

img = nib.load(nii_path)

# Convertimos a array NumPy
data = img.get_fdata()

# Mostramos información
print(f"Dimensiones de la imagen: {data.shape}")
print(f"Tipo de datos: {data.dtype}")

data_3d = data[:, :, :]  # Extraemos el volumen 3D

slice_x = data_3d.shape[0] // 2  # Corte Sagital
slice_y = data_3d.shape[1] // 2  # Corte Coronal
slice_z = data_3d.shape[2] // 2  # Corte Axial

fig, axes = plt.subplots(1, 3, figsize=(15, 5))

# Corte Coronal (Vista frontal)
axes[0].imshow(data_3d[slice_x, :, :], cmap="gray", origin="lower")
axes[0].set_title("Corte Coronal (Frontal)")

# Corte Axial (Vista superior/inferior)
axes[1].imshow(data_3d[:, slice_y, :], cmap="gray", origin="lower")
axes[1].set_title("Corte Axial (Superior)")

# Corte Sagital (Vista lateral)
axes[2].imshow(data_3d[:, :, slice_z], cmap="gray", origin="lower")
axes[2].set_title("Corte Sagital (Lateral)")

for ax in axes:
    ax.axis("off")

plt.show()

# Mostramos misma imagen pero con colores
import matplotlib.pyplot as plt
import nibabel as nib

slice_x = data_3d.shape[0] // 2  # Corte Sagital
slice_y = data_3d.shape[1] // 2  # Corte Coronal
slice_z = data_3d.shape[2] // 2  # Corte Axial

fig, axes = plt.subplots(1, 3, figsize=(15, 5))
colormap = "jet"

# Corte Coronal (Vista frontal)
axes[0].imshow(data_3d[slice_x, :, :], cmap=colormap, origin="lower")
axes[0].set_title("Corte Coronal (Frontal)")

# Corte Axial (Vista superior/inferior)
axes[1].imshow(data_3d[:, slice_y, :], cmap=colormap, origin="lower")
axes[1].set_title("Corte Axial (Superior)")

# Corte Sagital (Vista lateral)
axes[2].imshow(data_3d[:, :, slice_z], cmap=colormap, origin="lower")
axes[2].set_title("Corte Sagital (Lateral)")

for ax in axes:
    ax.axis("off")

plt.show()

# Tanto data como data_3d son matrices de datos numéricos y el slice es la forma original de ese campo dividido entre 2
print(slice_z)
print(data_3d[slice_x, :, :])

"""# 2. PREPARACIÓN CONJUNTO DE DATOS.

"""

import nibabel as nib
import numpy as np
import pandas as pd
import os
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
import tensorflow as tf
from scipy.ndimage import zoom

base_path = "/Volumes/T7/BrainLat/MRI data/BrainLat_dataset_NewIDs"

# Función para verificar si existe la imagen de 'T1'
def imagen_existente(mri_id):
    image_path = os.path.join(base_path, mri_id, 'anat', f"{mri_id}_T1w.nii.gz")
    return os.path.exists(image_path)

filtered_df["has_image"] = filtered_df["MRI_ID"].apply(imagen_existente)

# Nos quedamos solo con los que sí tienen imagen
filtered_df_with_image = filtered_df[filtered_df["has_image"] == True].copy()

label2id = {
    "AD": 0,
    "CN": 1,
    "PD": 2,
    "FTD": 3
}

TARGET_SHAPE = (64, 64, 40)

X = []
y = []
mri_ids = []

for i, row in filtered_df_with_image.iterrows():
    try:
        img_path = f"/Volumes/T7/BrainLat/MRI data/BrainLat_dataset_NewIDs/{row['MRI_ID']}/anat/{row['MRI_ID']}_T1w.nii.gz"
        img = nib.load(img_path)
        data = img.get_fdata()
        data_3d = data[:, :, :]
        # Para ocupar menos lugar
        data_3d = data_3d.astype(np.float32)

        # Normalizamos
        data_3d = (data_3d - np.mean(data_3d)) / np.std(data_3d)

        zoom_factors = (
            TARGET_SHAPE[0] / data_3d.shape[0],
            TARGET_SHAPE[1] / data_3d.shape[1],
            TARGET_SHAPE[2] / data_3d.shape[2]
        )

        # Redimensionamos el volumen
        data_3d_resized = zoom(data_3d, zoom_factors)

        # Expandimos el canal
        data_3d_resized = np.expand_dims(data_3d_resized, axis=-1)

        X.append(data_3d_resized)
        y.append(label2id[row['diagnosis']])
        mri_ids.append(row['MRI_ID'])  # Añadimos solo si se pudo procesar

    except Exception as e:
        print(f"Error procesando {row['MRI_ID']} ({row['diagnosis']}): {e}")

X = np.array(X)
y = np.array(y, dtype=np.int32)
mri_ids = np.array(mri_ids)
print(X.shape)  # Se muestra: (n_samples, 64, 64, 40, 1)
print(y.shape)

# Mostramos X para el individuo 1 con forma (64 para eje X, 64 para eje Y, 40 para eje X), su imagen es un cubo 3D con todo valores numéricos
print(X[1])

# Examinamos las clases que restan para imágenes tipo T1
conteo_diagnosticos = filtered_df_with_image['diagnosis'].value_counts()

print("Recuento de diagnósticos:")
print(conteo_diagnosticos)

"""# 3. PREPARACIÓN DE ETIQUETAS."""

# Codificamos etiquetas
encoder = LabelEncoder()
y_encoded = encoder.fit_transform(y)

# Ahora AD:0, CN:1 y FTD:2
print(y_encoded)

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test, train_ids, test_ids = train_test_split(X, y_encoded, mri_ids, test_size=0.2, stratify=y_encoded, random_state=42)

# Guardado
#from google.colab import drive
#drive.mount('/content/drive')

#np.savez_compressed("/content/drive/MyDrive/TFG/train_data.npz", X=X_train, y=y_train, ids=train_ids)
#np.savez_compressed("/content/drive/MyDrive/TFG/test_data.npz", X=X_test, y=y_test, ids=test_ids)

# Carga
from google.colab import drive
drive.mount('/content/drive')

train = np.load("/content/drive/MyDrive/TFG/train_data.npz", allow_pickle=True)
X_train = train["X"]
y_train = train["y"]
train_ids = train["ids"].astype(str)  # <-- 100% alineado: X_train[i] corresponde a y_train[i] y a train_ids[i], mismo orden

test = np.load("/content/drive/MyDrive/TFG/test_data.npz", allow_pickle=True)
X_test = test["X"]
y_test = test["y"]
test_ids = test["ids"].astype(str)

print(train)

# Carga y división variables demográficas
import pandas as pd
import numpy as np

df = pd.read_csv("/content/drive/MyDrive/TFG/BrainLat_Imputado3.csv", delimiter=";")
df["MRI_ID"] = df["MRI_ID"].astype(str)

# Filtramos únicamente los MRI_IDs presentes en los datos de imagen
filtered_df = df[df["MRI_ID"].isin(np.concatenate([train_ids, test_ids]))].copy()

# Dividimos en conjuntos train y test manteniendo el orden
df_train = filtered_df.set_index("MRI_ID").loc[train_ids].reset_index()
df_test = filtered_df.set_index("MRI_ID").loc[test_ids].reset_index()

df_train.shape, df_test.shape

df_train.head()

"""# 4. SELECCIÓN DE EMBEDDINGS PARA MRIs T1.

## 4.1. TIPO A: CNN Feature Extractor.
"""

from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Conv3D, MaxPooling3D, Flatten, Dense

input_layer = Input(shape=(64, 64, 40, 1))
x = Conv3D(16, (3, 3, 3), activation='relu', padding='same')(input_layer)
x = MaxPooling3D((2, 2, 2))(x)
x = Conv3D(32, (3, 3, 3), activation='relu', padding='same')(x) # Conv3D + MaxPooling3D: buena combinación para datos volumétricos como resonancias T1
x = MaxPooling3D((2, 2, 2))(x)
x = Flatten()(x)
x = Dense(128, activation='relu')(x)  # Este será nuestro embedding

# No sobreajustamos con redes gigantes innecesarias en datasets médicos pequeños
# Modelo extractor
cnn_model1 = Model(inputs=input_layer, outputs=x)

# Versión con posibles mejoras
from tensorflow.keras.layers import Input, Conv3D, MaxPooling3D, GlobalAveragePooling3D, Dense, BatchNormalization, Activation
from tensorflow.keras.models import Model

input_layer = Input(shape=(64, 64, 40, 1))
x = Conv3D(32, (3, 3, 3), padding='same')(input_layer)
x = BatchNormalization()(x)
x = Activation('relu')(x)
x = MaxPooling3D((2, 2, 2))(x)

x = Conv3D(64, (3, 3, 3), padding='same')(x)
x = BatchNormalization()(x)
x = Activation('relu')(x)
x = MaxPooling3D((2, 2, 2))(x)

x = GlobalAveragePooling3D()(x)
embedding = Dense(128, activation='relu')(x)

cnn_model2 = Model(inputs=input_layer, outputs=embedding)

embeddings_cnn1 = cnn_model1.predict(X_train, batch_size=16)
embeddings_cnn2 = cnn_model2.predict(X_train, batch_size=16)

"""## 4.2. TIPO B: PCA."""

from sklearn.decomposition import PCA
import matplotlib.pyplot as plt
import numpy as np

# Aplanamos primero: (n_samples, 64*64*40)
X_flat = X_train.reshape((X_train.shape[0], -1))

# Aplicamos PCA sin limitar componentes
pca_full = PCA().fit(X_flat)

# Varianza acumulada
cum_var_exp = np.cumsum(pca_full.explained_variance_ratio_)

# Elegimos el número de componentes que explica al menos el 95% de la varianza
n_components_optimo = np.argmax(cum_var_exp >= 0.95) + 1

# Graficamos
plt.figure(figsize=(8, 4))
plt.plot(cum_var_exp, marker='o')
plt.axhline(0.95, color='r', linestyle='--')
plt.axvline(n_components_optimo, color='g', linestyle='--')
plt.title("Varianza explicada acumulada")
plt.xlabel("Número de componentes")
plt.ylabel("Varianza acumulada")
plt.grid(True)
plt.show()

print(f"Número óptimo de componentes (≥95% varianza): {n_components_optimo}")

pca = PCA(n_components=207)
embeddings_pca = pca.fit_transform(X_flat)

"""## 4.3. TIPO C: Autoencoder."""

from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Conv3D, MaxPooling3D, UpSampling3D

input_layer = Input(shape=(64, 64, 40, 1))
x = Conv3D(16, (3, 3, 3), activation='relu', padding='same')(input_layer)
x = MaxPooling3D((2, 2, 2), padding='same')(x)
x = Conv3D(8, (3, 3, 3), activation='relu', padding='same')(x)
encoded = MaxPooling3D((2, 2, 2), padding='same')(x)

# Decoder
x = Conv3D(8, (3, 3, 3), activation='relu', padding='same')(encoded)
x = UpSampling3D((2, 2, 2))(x)
x = Conv3D(16, (3, 3, 3), activation='relu')(x)
x = UpSampling3D((2, 2, 2))(x)
decoded = Conv3D(1, (3, 3, 3), activation='sigmoid', padding='same')(x)

autoencoder = Model(input_layer, decoded)
encoder_model = Model(inputs=input_layer, outputs=encoded)

embeddings_ae = encoder_model.predict(X_train)
embeddings_ae_flat = embeddings_ae.reshape((X_train.shape[0], -1))

"""## 4.4. Aspecto embeddings."""

print("Aspecto embedding con CNN: ", embeddings_cnn1)
print("Aspecto embedding con PCA: ", embeddings_pca)
print("Aspecto embedding con Autoencoder flat: ", embeddings_ae_flat)

"""# 5. ENTRENAMIENTO DE MODELOS.

## 5.1. BLOQUE A: Tests cognitivos + variables demográficas.
"""

import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.neural_network import MLPClassifier
from sklearn.cross_decomposition import PLSRegression
from sklearn.metrics import accuracy_score, f1_score, classification_report
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import train_test_split
from imblearn.pipeline import Pipeline
from imblearn.over_sampling import SMOTE
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder
from sklearn.base import BaseEstimator, ClassifierMixin

# CLASE ENVOLTORIO PARA PLS-DA (PLS + LDA)
class PLS_DA(BaseEstimator, ClassifierMixin):
    def __init__(self, n_components=2):
        self.n_components = n_components
        self.pls = PLSRegression(n_components=n_components)
        self.clf = LinearDiscriminantAnalysis()

    def fit(self, X, y):
        self.pls.fit(X, y)
        X_pls = self.pls.transform(X)
        self.clf.fit(X_pls, y)
        return self

    def predict(self, X):
        X_pls = self.pls.transform(X)
        return self.clf.predict(X_pls)

# 1. Variables del Bloque A
demograficas = ["sex", "Age", "years_education", "laterality", "country", "center"]
cognitivos = [
    "ifs_total_score", "ifs_motor_series", "ifs_conflicting_instructions",
    "ifs_motor_inhibition", "ifs_digits", "ifs_months", "ifs_visual_wm",
    "ifs_proverb", "ifs_verbal_inhibition", "mini_sea_fer", "mini_sea_tom"
]
df_cols = demograficas + cognitivos

# 2. Selección columnas
df_y_train = df_train["diagnosis"].map({
    "AD": 0,
    "CN": 1,
    "FTD": 2
})
df_y_test = df_test["diagnosis"].map({
    "AD": 0,
    "CN": 1,
    "FTD": 2
})
df_train_bloqueA = df_train[df_cols]
df_test_bloqueA = df_test[df_cols]

# 3. Preprocesamiento
categorical_cols = ["sex", "laterality", "country", "center"]
numerical_cols = ["Age", "years_education"] + cognitivos

preprocessor = ColumnTransformer([
    ("num", StandardScaler(), numerical_cols),
    ("cat", OneHotEncoder(drop='first'), categorical_cols)
])

# 4. Modelos
modelos = {
    "Random Forest": RandomForestClassifier(n_estimators=100, random_state=42),
    "SVM": SVC(kernel='linear', probability=True),
    "LDA": LinearDiscriminantAnalysis(),
    "MLP (NN)": MLPClassifier(hidden_layer_sizes=(64,), max_iter=500, random_state=42),
    "PLS-DA": PLS_DA(n_components=4)
}

# 5. Entrenamiento y evaluación
for nombre, modelo in modelos.items():
    # Aplicamos oversampling con smote para el balanceo de datos
    pipeline = Pipeline([
        ("preproc", preprocessor),
        ("smote", SMOTE(random_state=42)),
        ("clf", modelo)
    ])
    pipeline.fit(df_train_bloqueA, df_y_train)
    y_pred = pipeline.predict(df_test_bloqueA)

    acc = accuracy_score(df_y_test, y_pred)
    f1 = f1_score(df_y_test, y_pred, average="weighted")

    print(f"\n=== {nombre} ===")
    print(f"Accuracy: {acc:.4f}")
    print(f"F1-score: {f1:.4f}")
    print(classification_report(df_y_test, y_pred))

"""## 5.2. BLOQUE B: Embeddings A, B y C.

"""

import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.neural_network import MLPClassifier
from sklearn.cross_decomposition import PLSRegression
from sklearn.metrics import accuracy_score, f1_score, classification_report
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from imblearn.over_sampling import SMOTE
from sklearn.base import BaseEstimator, ClassifierMixin

# CLASE PARA PLS-DA
class PLS_DA(BaseEstimator, ClassifierMixin):
    def __init__(self, n_components=5):
        self.n_components = n_components
        self.pls = PLSRegression(n_components=n_components)
        self.clf = LinearDiscriminantAnalysis()

    def fit(self, X, y):
        self.pls.fit(X, y)
        X_pls = self.pls.transform(X)
        self.clf.fit(X_pls, y)
        return self

    def predict(self, X):
        X_pls = self.pls.transform(X)
        return self.clf.predict(X_pls)

# 1. Carga de datos
train = np.load("/content/drive/MyDrive/TFG/train_data.npz", allow_pickle=True)
X_train = train["X"]
y_train = train["y"]
train_ids = train["ids"]

test = np.load("/content/drive/MyDrive/TFG/test_data.npz", allow_pickle=True)
X_test = test["X"]
y_test = test["y"]
test_ids = test["ids"]

embeddings_cnn1_train = embeddings_cnn1
embeddings_cnn2_train = embeddings_cnn2
embeddings_cnn1_test = cnn_model1.predict(X_test, batch_size=16)
embeddings_cnn2_test = cnn_model2.predict(X_test, batch_size=16)

embeddings_pca_train = embeddings_pca
X_test_flat = X_test.reshape((X_test.shape[0], -1))
embeddings_pca_test = pca.transform(X_test_flat)

embeddings_ae_flat_train = embeddings_ae_flat
embeddings_ae_test = encoder_model.predict(X_test)
embeddings_ae_flat_test = embeddings_ae_test.reshape((X_test.shape[0], -1))

# 2. Escalado global
scaler = StandardScaler()
X_trainA1 = scaler.fit_transform(embeddings_cnn1_train)
X_testA1 = scaler.transform(embeddings_cnn1_test)
scaler2 = StandardScaler()
X_trainA2 = scaler2.fit_transform(embeddings_cnn2_train)
X_testA2 = scaler2.transform(embeddings_cnn2_test)

scaler3 = StandardScaler()
X_trainB = scaler3.fit_transform(embeddings_pca_train)
X_testB = scaler3.transform(embeddings_pca_test)

scaler4 = StandardScaler()
X_trainC = scaler4.fit_transform(embeddings_ae_flat_train)
X_testC = scaler4.transform(embeddings_ae_flat_test)

# 3. Modelos a comparar
modelos = {
    "Random Forest": RandomForestClassifier(n_estimators=100, random_state=42),
    "SVM": SVC(kernel='linear', probability=True),
    "LDA": LinearDiscriminantAnalysis(),
    "MLP (NN)": MLPClassifier(hidden_layer_sizes=(64,), max_iter=500, random_state=42),
    "PLS-DA": PLS_DA(n_components=5)
}

# 4. Entrenamiento y evaluación
embeddings_datasets = {
    "CNN1": (X_trainA1, X_testA1),
    "CNN2": (X_trainA2, X_testA2),
    "PCA": (X_trainB, X_testB),
    "Autoencoder": (X_trainC, X_testC)
}
for emb,conj in embeddings_datasets.items():
  print(f"{emb}")
  # Aplicamos oversampling solo a las muestras de entrenamiento
  smote = SMOTE(random_state=42)
  X_train_balanced, y_train_balanced = smote.fit_resample(conj[0], y_train)
  for nombre, modelo in modelos.items():
      modelo.fit(X_train_balanced, y_train_balanced)
      y_pred = modelo.predict(conj[1])

      acc = accuracy_score(y_test, y_pred)
      f1 = f1_score(y_test, y_pred, average="weighted")

      print(f"\n=== {nombre} ===")
      print(f"Accuracy: {acc:.4f}")
      print(f"F1-score: {f1:.4f}")
      print(classification_report(y_test, y_pred))

import pandas as pd

# Tabla con los mejores resultados (sesión 1 -> VERSIÓN ANTIGUA)
data = {
    "Embedding": ["CNN1", "CNN2", "PCA", "Autoencoder"],
    "Mejor Modelo": ["Random Forest", "MLP (NN)", "SVM", "Random Forest"],
    "Accuracy": [0.6557, 0.7213, 0.7213, 0.7213],
    "F1-score": [0.6369, 0.7218, 0.7153, 0.7092]
}

tabla_resumen = pd.DataFrame(data)

print("=== Tabla resumen de desempeño por embedding ===")
print(tabla_resumen.to_string(index=False))

"""El mejor embedding es CNN2, seguido de cerca por PCA y luego Autoencoder, porque:

- CNN2 con MLP ofrece el mejor equilibrio entre clases, mayor robustez y F1 más alto.

- PCA es muy competitivo y puede ser preferido si se busca interpretabilidad.

- Autoencoder es una buena opción si quieres preservar una representación no lineal, aunque ligeramente inferior.
"""

import pandas as pd

# Tabla actualizada con los mejores resultados reales (resultados segunda sesión -> modelos guardados)
data = {
    "Embedding": ["CNN1", "CNN2", "PCA", "Autoencoder"],
    "Mejor Modelo": ["Random Forest", "Random Forest", "SVM", "MLP (NN)"],
    "Accuracy": [0.7377, 0.6557, 0.7213, 0.6721],
    "F1-score": [0.7310, 0.6524, 0.7153, 0.6715]
}

tabla_resumen = pd.DataFrame(data)

print("=== Tabla resumen de desempeño por embedding ===")
print(tabla_resumen.to_string(index=False))

"""El mejor embedding es CNN1, seguido de cerca por PCA y luego Autoencoder, porque:

- CNN1 con Random Forest ofrece el mejor equilibrio entre clases, mayor robustez y F1 más alto.
- PCA es muy competitivo y puede ser preferido si se desea interpretabilidad.
- Autoencoder es una buena opción si quieres preservar una representación no lineal, aunque ligeramente inferior.
"""

# Aplicamos cross validation porque resulta sospechoso que el modelo CNN1 sea mejor que CNN2, el cual es igual, pero con mejoras introducidas
import numpy as np
import pandas as pd
from sklearn.model_selection import cross_val_score, StratifiedKFold
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.neural_network import MLPClassifier
from sklearn.preprocessing import StandardScaler

# Escalamos los embeddings
scaler = StandardScaler()
cnn1 = scaler.fit_transform(embeddings_cnn1_train)
cnn2 = scaler.fit_transform(embeddings_cnn2_train)
pca  = scaler.fit_transform(embeddings_pca_train)
ae   = scaler.fit_transform(embeddings_ae_flat_train)

# Diccionario con mejores modelos por embedding
mejores_modelos = {
    "CNN1": (cnn1, RandomForestClassifier(n_estimators=100, random_state=42)),
    "CNN2": (cnn2, RandomForestClassifier(n_estimators=100, random_state=42)),
    "PCA":  (pca,  SVC(kernel='linear')),
    "Autoencoder": (ae, RandomForestClassifier(n_estimators=100, random_state=42))
}

# Cross-validation
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

resultados_cv = []
for nombre, (X, modelo) in mejores_modelos.items():
    acc_scores = cross_val_score(modelo, X, y_train, cv=cv, scoring='accuracy')
    f1_scores = cross_val_score(modelo, X, y_train, cv=cv, scoring='f1_weighted')

    resultados_cv.append({
        "Embedding": nombre,
        "Mejor Modelo": type(modelo).__name__,
        "Accuracy (CV)": np.mean(acc_scores),
        "F1-score (CV)": np.mean(f1_scores)
    })

# Creamos DataFrame resumen
tabla_cv = pd.DataFrame(resultados_cv)
print("=== Resultados con Validación Cruzada (5-Fold) ===")
print(tabla_cv.to_string(index=False))

"""Finalmente, la mejor opción para obtener embeddings sería CNN con diferencia con Random Forest. Se hará uso de este embedding en el entrenamiento de los datos que constituyen el bloque C.

## 5.3. BLOQUE C: Tests cognitivos + variables demográficas + mejor embedding.
"""

import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer

# 1. Datos preparados bloque A
# df_train_bloqueA
# df_test_bloqueA

# 2. Preprocesamiento
preprocessor = ColumnTransformer([
    ("num", StandardScaler(), numerical_cols),
    ("cat", OneHotEncoder(drop='first'), categorical_cols)
])

df_trainA_proc = preprocessor.fit_transform(df_train_bloqueA)
df_testA_proc = preprocessor.transform(df_test_bloqueA)

# 3. Concatenación
X_train_concat = np.concatenate([df_trainA_proc, embeddings_cnn2_train], axis=1)
X_test_concat = np.concatenate([df_testA_proc, embeddings_cnn2_test], axis=1)

print(df_trainA_proc[1]) # 13 numéricas escaladas, 2 binarias y 2 categóricas a las que se les aplica el one-hot encoding

import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.neural_network import MLPClassifier
from sklearn.cross_decomposition import PLSRegression
from sklearn.metrics import accuracy_score, f1_score, classification_report
from sklearn.preprocessing import StandardScaler
from sklearn.base import BaseEstimator, ClassifierMixin
from imblearn.over_sampling import SMOTE

# Clase para PLS-DA
class PLS_DA(BaseEstimator, ClassifierMixin):
    def __init__(self, n_components=5):
        self.n_components = n_components
        self.pls = PLSRegression(n_components=n_components)
        self.clf = LinearDiscriminantAnalysis()

    def fit(self, X, y):
        self.pls.fit(X, y)
        X_pls = self.pls.transform(X)
        self.clf.fit(X_pls, y)
        return self

    def predict(self, X):
        X_pls = self.pls.transform(X)
        return self.clf.predict(X_pls)

# Normalización de los datos combinados
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train_concat)
X_test_scaled = scaler.transform(X_test_concat)

# Modelos a evaluar
modelos = {
    "Random Forest": RandomForestClassifier(n_estimators=100, random_state=42),
    "SVM (Linear)": SVC(kernel='linear', probability=True),
    "LDA": LinearDiscriminantAnalysis(),
    "MLP (NN)": MLPClassifier(hidden_layer_sizes=(64,), max_iter=500, random_state=42),
    "PLS-DA": PLS_DA(n_components=5)
}

# Entrenamiento y evaluación
resultados = []

# Aplicamos oversampling solo a las muestras de entrenamiento
smote = SMOTE(random_state=42)
X_train_scaled_balanced, y_train_balanced = smote.fit_resample(X_train_scaled, y_train)

for nombre, modelo in modelos.items():
    modelo.fit(X_train_scaled_balanced, y_train_balanced)
    y_pred = modelo.predict(X_test_scaled)

    acc = accuracy_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred, average="weighted")

    print(f"\n=== {nombre} ===")
    print(f"Accuracy: {acc:.4f}")
    print(f"F1-score: {f1:.4f}")
    print(classification_report(y_test, y_pred))

    resultados.append({
        "Modelo": nombre,
        "Accuracy": acc,
        "F1-score": f1
    })

# Mostrar resultados en tabla
df_resultados = pd.DataFrame(resultados)
print("\nResumen comparativo:")
print(df_resultados)

# VERSIÓN ANTIGUA (sesión 1)
import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.neural_network import MLPClassifier
from sklearn.cross_decomposition import PLSRegression
from sklearn.metrics import accuracy_score, f1_score, classification_report
from sklearn.preprocessing import StandardScaler
from sklearn.base import BaseEstimator, ClassifierMixin
from imblearn.over_sampling import SMOTE

# Clase para PLS-DA
class PLS_DA(BaseEstimator, ClassifierMixin):
    def __init__(self, n_components=5):
        self.n_components = n_components
        self.pls = PLSRegression(n_components=n_components)
        self.clf = LinearDiscriminantAnalysis()

    def fit(self, X, y):
        self.pls.fit(X, y)
        X_pls = self.pls.transform(X)
        self.clf.fit(X_pls, y)
        return self

    def predict(self, X):
        X_pls = self.pls.transform(X)
        return self.clf.predict(X_pls)

# Normalización de los datos combinados
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train_concat)
X_test_scaled = scaler.transform(X_test_concat)

# Modelos a evaluar
modelos = {
    "Random Forest": RandomForestClassifier(n_estimators=100, random_state=42),
    "SVM (Linear)": SVC(kernel='linear', probability=True),
    "LDA": LinearDiscriminantAnalysis(),
    "MLP (NN)": MLPClassifier(hidden_layer_sizes=(64,), max_iter=500, random_state=42),
    "PLS-DA": PLS_DA(n_components=5)
}

# Entrenamiento y evaluación
resultados = []

# Aplicamos oversampling solo a las muestras de entrenamiento
smote = SMOTE(random_state=42)
X_train_scaled_balanced, y_train_balanced = smote.fit_resample(X_train_scaled, y_train)

for nombre, modelo in modelos.items():
    modelo.fit(X_train_scaled_balanced, y_train_balanced)
    y_pred = modelo.predict(X_test_scaled)

    acc = accuracy_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred, average="weighted")

    print(f"\n=== {nombre} ===")
    print(f"Accuracy: {acc:.4f}")
    print(f"F1-score: {f1:.4f}")
    print(classification_report(y_test, y_pred))

    resultados.append({
        "Modelo": nombre,
        "Accuracy": acc,
        "F1-score": f1
    })

# Mostrar resultados en tabla
df_resultados = pd.DataFrame(resultados)
print("\nResumen comparativo:")
print(df_resultados)

"""¿Por qué ha funcionado tan bien el MLP?

**1. Capacidad de modelar relaciones no lineales:** A diferencia de LDA o SVM lineal, un MLP con capas ocultas puede aprender interacciones complejas entre variables numéricas, categóricas y los embeddings.

**2. Combinación rica de información:**
  - Los embeddings CNN resumen patrones espaciales relevantes de las imágenes.
  - Las variables cognitivas y demográficas agregan información clínica contextual muy valiosa.
  - Esta combinación puede haber capturado tanto biomarcadores funcionales como perfil cognitivo-demográfico.

**3. Preprocesamiento adecuado:**
  - Escalado y codificación bien hechos.
  - Se aplicó balanceo de clases, reduciendo sesgos.

## 5.4. CNN2: Clasificación MRIs ponderadas en T1.
"""

import numpy as np
from tensorflow.keras.layers import Input, Conv3D, MaxPooling3D, GlobalAveragePooling3D, Dense, BatchNormalization, Activation
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.utils import to_categorical
from sklearn.metrics import classification_report, accuracy_score, f1_score
from tensorflow.keras.callbacks import EarlyStopping

# Carga de datos
train = np.load("/content/drive/MyDrive/TFG/train_data.npz", allow_pickle=True)
X_train = train["X"]
y_train = train["y"]
train_ids = train["ids"].astype(str)

test = np.load("/content/drive/MyDrive/TFG/test_data.npz", allow_pickle=True)
X_test = test["X"]
y_test = test["y"]
test_ids = test["ids"].astype(str)

# Aseguramos forma y tipo
X_train = X_train.astype(np.float32)
X_test = X_test.astype(np.float32)
y_train_cat = to_categorical(y_train, num_classes=3)
y_test_cat = to_categorical(y_test, num_classes=3)

# Red para clasificación (se trata de la CNN2)
input_layer = Input(shape=(64, 64, 40, 1))
x = Conv3D(32, (3, 3, 3), padding='same')(input_layer)
x = BatchNormalization()(x)
x = Activation('relu')(x)
x = MaxPooling3D((2, 2, 2))(x)

x = Conv3D(64, (3, 3, 3), padding='same')(x)
x = BatchNormalization()(x)
x = Activation('relu')(x)
x = MaxPooling3D((2, 2, 2))(x)

x = GlobalAveragePooling3D()(x)
x = Dense(128, activation='relu')(x)
output_layer = Dense(3, activation='softmax')(x)

cnn_classifier = Model(inputs=input_layer, outputs=output_layer)
cnn_classifier.compile(optimizer=Adam(learning_rate=0.001),
                       loss='categorical_crossentropy',
                       metrics=['accuracy'])

# Entrenamiento
early_stop = EarlyStopping(patience=10, restore_best_weights=True)
cnn_classifier.fit(X_train, y_train_cat,
                   validation_data=(X_test, y_test_cat),
                   epochs=50,
                   batch_size=16,
                   callbacks=[early_stop],
                   verbose=2)

# Evaluación
y_pred_probs = cnn_classifier.predict(X_test)
y_pred = np.argmax(y_pred_probs, axis=1)
acc = accuracy_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred, average="weighted")
report = classification_report(y_test, y_pred, digits=4)

(acc, f1, report)

# Resultados clasificación MRIs con CNN2
import pandas as pd

data = {
    "Clase": ["AD", "CN", "FTD", "Global"],
    "Precision": [0.6053, 0.5385, 0.6000, 0.5810],
    "Recall": [0.9200, 0.3333, 0.4000, 0.5902],
    "F1-score": [0.7302, 0.4118, 0.4800, 0.5590],
    "Support": [25, 21, 15, 61]
}

tabla_metrica_clase = pd.DataFrame(data)

print("=== Métricas por clase para CNN2 ===")
print(tabla_metrica_clase.to_string(index=False))

"""- Tendencia hacia AD: el clasificador está muy ajustado para identificar AD (puede ser debido a la mayor cantidad de AD en los datos o por patrones más claros).

- Desbalance y superposición de clases: CN y FTD suelen cruzarse en el espacio latente que ha sido aprendido por el modelo, complicando su diferenciación precisa.

- Interpretación clínica: podríamos señalar que el modelo es eficaz para identificar AD, pero debe perfeccionarse en la diferenciación de casos sanos o FTD para prevenir falsos negativos

El rendimiento global de la clasificación directa de las imágenes de resonancia magnética con CNN2 no resulta satisfactorio, por lo que se obvia esta opción y se procede con los embeddings + tests cognitivos + variables demográficas.

# 6. INTERPRETACIÓN DEL MEJOR MODELO APLICADO AL BLOQUE C: MLP (NN).
"""

import numpy as np
import pandas as pd
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score, f1_score, classification_report
from sklearn.preprocessing import StandardScaler
from imblearn.over_sampling import SMOTE

# 1. Normalización
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train_concat)
X_test_scaled = scaler.transform(X_test_concat)

# 2. Balanceo del conjunto de entrenamiento
smote = SMOTE(random_state=42)
X_train_balanced, y_train_balanced = smote.fit_resample(X_train_scaled, y_train)

# 3. Definición y entrenamiento del modelo
mlp_model = MLPClassifier(hidden_layer_sizes=(64,), max_iter=500, random_state=42)
mlp_model.fit(X_train_balanced, y_train_balanced)

# 4. Evaluación
y_pred = mlp_model.predict(X_test_scaled)
acc = accuracy_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred, average="weighted")

# 5. Resultados
print("\n=== MLP (NN) ===")
print(f"Accuracy: {acc:.4f}")
print(f"F1-score: {f1:.4f}")
print(classification_report(y_test, y_pred))

# 6. Tabla resumen
df_resultado = pd.DataFrame([{
    "Modelo": "MLP (NN)",
    "Accuracy": acc,
    "F1-score": f1
}])
print("\nResumen:")
print(df_resultado)

# VERSIÓN ANTIGUA (sesión 1)
import numpy as np
import pandas as pd
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score, f1_score, classification_report
from sklearn.preprocessing import StandardScaler
from imblearn.over_sampling import SMOTE

# 1. Normalización
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train_concat)
X_test_scaled = scaler.transform(X_test_concat)

# 2. Balanceo del conjunto de entrenamiento
smote = SMOTE(random_state=42)
X_train_balanced, y_train_balanced = smote.fit_resample(X_train_scaled, y_train)

# 3. Definición y entrenamiento del modelo
mlp_model = MLPClassifier(hidden_layer_sizes=(64,), max_iter=500, random_state=42)
mlp_model.fit(X_train_balanced, y_train_balanced)

# 4. Evaluación
y_pred = mlp_model.predict(X_test_scaled)
acc = accuracy_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred, average="weighted")

# 5. Resultados
print("\n=== MLP (NN) ===")
print(f"Accuracy: {acc:.4f}")
print(f"F1-score: {f1:.4f}")
print(classification_report(y_test, y_pred))

# 6. Tabla resumen
df_resultado = pd.DataFrame([{
    "Modelo": "MLP (NN)",
    "Accuracy": acc,
    "F1-score": f1
}])
print("\nResumen:")
print(df_resultado)

import shap
import pandas as pd

# 1. Recuperamos nombres de las variables del bloque A
onehot_feature_names = preprocessor.named_transformers_["cat"].get_feature_names_out(categorical_cols)
feature_names_tabular = numerical_cols + list(onehot_feature_names)
all_feature_names = feature_names_tabular + [f"emb_{i}" for i in range(embeddings_cnn2_train.shape[1])]

# 2. Creamos DataFrames con nombres
X_train_df = pd.DataFrame(X_train_scaled, columns=all_feature_names)
X_test_df = pd.DataFrame(X_test_scaled, columns=all_feature_names)

# 3. Aplicamos SHAP values (SHapley Additive exPlanations): más usado en redes neuronales
explainer = shap.KernelExplainer(mlp_model.predict, X_train_df)
shap_values = explainer.shap_values(X_test_df[:50])
shap.summary_plot(shap_values, X_test_df[:50])

"""El gráfico SHAP representa la importancia y dirección del impacto de cada variable sobre las predicciones del modelo MLP entrenado con:

- Embeddings de MRI (CNN2)
- Variables demográficas
- Tests cognitivos

Cada punto representa una observación (paciente). El eje horizontal indica el valor SHAP, es decir, cuánto contribuye esa variable a aumentar o disminuir la probabilidad de una clase (por ejemplo, diagnóstico de AD). El color indica el valor de la variable (rojo: alto, azul: bajo).

Variables más influyentes

Edad (Age)
- La variable con mayor impacto.
- Valores altos (edad avanzada) se asocian a un desplazamiento del valor SHAP hacia la izquierda, lo que indica una mayor probabilidad de diagnóstico patológico. Esto es coherente con la mayor prevalencia de deterioro cognitivo en edades avanzadas.

Centro y país de procedencia (center_PE, country_CO, country_PE)
- Estas variables muestran una influencia significativa.
- Esto puede reflejar diferencias regionales en criterios de inclusión, protocolos clínicos o perfiles poblacionales. También podría indicar sesgos en los datos recogidos por centro.

Tests cognitivos (ifs_*, mini_sea_*)
- Los resultados de pruebas como ifs_verbal_inhibition, ifs_conflicting_instructions, mini_sea_fer y mini_sea_tom tienen un peso importante.
- Valores altos de estos tests desplazan el SHAP hacia la derecha, lo que indica un menor riesgo de diagnóstico patológico, mientras que valores bajos (peor rendimiento) están asociados a una mayor probabilidad de enfermedad.
- Esto valida el modelo, ya que estas pruebas están diseñadas para detectar deterioro cognitivo.

Embeddings (emb_*)
- Varios componentes del embedding aparecen entre las variables más relevantes (emb_18, emb_38, etc.).
- Aunque no son directamente interpretables, estos vectores provienen de una CNN entrenada sobre resonancias T1, por lo que podrían reflejar patrones anatómicos asociados a los distintos diagnósticos.
"""

# Reducción de dimensionalidad con t-SNE o UMAP: búsqueda biomarcadores 1
from sklearn.manifold import TSNE
import matplotlib.pyplot as plt

tsne = TSNE(n_components=2, random_state=42)
X_embedded = tsne.fit_transform(embeddings_cnn2_train)

plt.scatter(X_embedded[:, 0], X_embedded[:, 1], c=y_train, cmap='viridis')
plt.title("Proyección t-SNE de los embeddings CNN2")
plt.xlabel("Dim 1")
plt.ylabel("Dim 2")
plt.colorbar(label="Clase")
plt.show()

# Aplicación Grad-Cam: búsqueda biomarcadores 2
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Conv3D, MaxPooling3D, GlobalAveragePooling3D, Dense, BatchNormalization, Activation

input_layer = Input(shape=(64, 64, 40, 1))
x = Conv3D(32, (3, 3, 3), padding='same', name="conv1")(input_layer)
x = BatchNormalization()(x)
x = Activation('relu')(x)
x = MaxPooling3D((2, 2, 2))(x)

x = Conv3D(64, (3, 3, 3), padding='same', name="conv2")(x)
x = BatchNormalization()(x)
x = Activation('relu')(x)
x = MaxPooling3D((2, 2, 2))(x)

x = GlobalAveragePooling3D(name="gap")(x)
x = Dense(128, activation='relu')(x)
output = Dense(3, activation='softmax', name="classifier")(x)

model_full = Model(inputs=input_layer, outputs=output)

import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
import scipy.ndimage

# Suponiendo que tienes model_full entrenado y X_test (MRI 3D input)
img = X_test[0:1]

# Grad-CAM
grad_model = Model(inputs=model_full.inputs,
                   outputs=[model_full.get_layer("conv2").output, model_full.output])

with tf.GradientTape() as tape:
    conv_outputs, predictions = grad_model(img)
    pred_index = tf.argmax(predictions[0])
    loss = predictions[:, pred_index]

# Gradiente de salida con respecto a la última capa conv
grads = tape.gradient(loss, conv_outputs)[0]
pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2, 3))

# Ponderamos la activación por los gradientes medios
conv_outputs = conv_outputs[0]
heatmap = tf.reduce_sum(tf.multiply(pooled_grads, conv_outputs), axis=-1).numpy()

# Normalizamos heatmap y redimensionamos a volumen original
heatmap = np.maximum(heatmap, 0)
heatmap /= np.max(heatmap)
heatmap_resized = scipy.ndimage.zoom(heatmap, zoom=(4, 4, 5.33))  # para (64,64,40)

# Mostrar cortes centrales (axial)
z_idx = heatmap_resized.shape[2] // 2
plt.imshow(heatmap_resized[:, :, z_idx], cmap='jet')
plt.title(f"Grad-CAM para clase predicha: {int(pred_index)}")
plt.axis('off')
plt.colorbar()
plt.show()

import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
import scipy.ndimage

img = X_test[0:1]  # Tiene shape (1, 64, 64, 40, 1)

def generate_gradcam(model, img, target_class, conv_layer_name="conv2"):
    grad_model = tf.keras.models.Model(
        inputs=model.inputs,
        outputs=[model.get_layer(conv_layer_name).output, model.output]
    )

    with tf.GradientTape() as tape:
        conv_outputs, predictions = grad_model(img)
        loss = predictions[:, target_class]  # Para forzar la clase que queremos analizar

    grads = tape.gradient(loss, conv_outputs)[0]
    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2, 3))
    conv_outputs = conv_outputs[0]
    heatmap = tf.reduce_sum(tf.multiply(pooled_grads, conv_outputs), axis=-1).numpy()
    heatmap = np.maximum(heatmap, 0)
    heatmap /= np.max(heatmap)
    return scipy.ndimage.zoom(heatmap, zoom=(4, 4, 5.33))  # Para ajustar a 64x64x40

# Generamos y visualizamos para clase 0 (AD)
heatmap_AD = generate_gradcam(model_full, img, target_class=0)
z = heatmap_AD.shape[2] // 2
plt.imshow(heatmap_AD[:, :, z], cmap='jet')
plt.title("Grad-CAM para clase AD (0)")
plt.colorbar()
plt.axis('off')
plt.show()

# Generamos y visualizamos para clase 2 (FTD)
heatmap_FTD = generate_gradcam(model_full, img, target_class=2)
z = heatmap_FTD.shape[2] // 2
plt.imshow(heatmap_FTD[:, :, z], cmap='jet')
plt.title("Grad-CAM para clase FTD (2)")
plt.colorbar()
plt.axis('off')
plt.show()

"""Los mapas de calor representan los cerebros de pacientes con distintos perfiles observados con una vista axial, es decir, superior. La interpretación de las imágenes resultantes con posibles biomarcadores es la siguiente:

**1. Clase 1 -- CN (Control Normal):**
- La activación es leve y dispersa, con pequeños focos en áreas periféricas, particularmente en el cerebelo y la corteza occipital.
- Este patrón indica que el modelo no detecta señales patológicas evidentes: se basa en la falta de atrofia o cambios estructurales significativos, lo que concuerda con un perfil saludable.
- Se trata de un patrón de activación más "neutral" y universal

**2. Clase 0 -- AD (Alzheimer):**
- La activación se enfoca en áreas más internas y bilaterales, particularmente en:
  - Lóbulos temporales mediales (región del hipocampo).
  - Parietal inferior y subcorticales.
- Estas áreas son biomarcadores tradicionales en AD: el modelo ha logrado identificarlas como rasgos del deterioro relacionado con el Alzheimer.
- Activación intensa y localizada, lo que sugiere una señal anatómica robusta

**3. Clase 2 -- FTD (Frontotemporal Dementia):**
- El patrón es bastante parecido al de AD, pero se puede distinguir por:
  - Mayor influencia en áreas frontales o laterales prefrontales.
  - Regiones más elevadas, lo que coincide con la atrofia frontotemporal característica de FTD.
- La activación es igualmente clara y precisa, aunque está más alejada en comparación con la de AD.
"""

# Mostrar Grad-CAM para las primeras N personas con diagnóstico AD (clase 0)
num_muestras = 5
contador = 0

for i in range(len(y_test)):
    if y_test[i] == 0:       # Solo clase AD
        img = X_test[i:i+1]  # Mantener shape (1, 64, 64, 40, 1)
        heatmap = generate_gradcam(model_full, img, target_class=0)
        z = heatmap.shape[2] // 2  # Corte axial central

        plt.imshow(heatmap[:, :, z], cmap='jet')
        plt.title(f"Grad-CAM clase AD (0) - paciente {i}")
        plt.colorbar()
        plt.axis('off')
        plt.show()

        contador += 1
        if contador >= num_muestras:
            break

# Mostrar Grad-CAM para las primeras N personas con diagnóstico CN (clase 1)
num_muestras = 5
contador = 0

for i in range(len(y_test)):
    if y_test[i] == 1:       # Solo clase CN
        img = X_test[i:i+1]  # Mantener shape (1, 64, 64, 40, 1)
        heatmap = generate_gradcam(model_full, img, target_class=0)
        z = heatmap.shape[2] // 2  # Corte axial central

        plt.imshow(heatmap[:, :, z], cmap='jet', origin='lower')
        plt.title(f"Grad-CAM clase CN (1) - paciente {i}")
        plt.colorbar()
        plt.axis('off')
        plt.show()

        contador += 1
        if contador >= num_muestras:
            break

# Mostrar Grad-CAM para las primeras N personas con diagnóstico FTD (clase 2)
num_muestras = 5
contador = 0

for i in range(len(y_test)):
    if y_test[i] == 2:       # Solo clase FTD
        img = X_test[i:i+1]  # Mantener shape (1, 64, 64, 40, 1)
        heatmap = generate_gradcam(model_full, img, target_class=0)
        z = heatmap.shape[2] // 2  # Corte axial central

        plt.imshow(heatmap[:, :, z], cmap='jet', origin='lower')
        plt.title(f"Grad-CAM clase FTD (2) - paciente {i}")
        plt.colorbar()
        plt.axis('off')
        plt.show()

        contador += 1
        if contador >= num_muestras:
            break

"""| Paciente | Clase real | Zonas activadas      | ¿Coincide con otros de su clase? |
| -------- | ---------- | -------------------- | ------------------------------- |
| ...        | CN         | Occipital + cerebelo | Parcialmente                    |
| ...      | AD         | Temporal medial      | Sí                              |
| ...      | FTD        | Frontal lateral      | Parcialmente, sobre todo frontal                              |

"""

import joblib

# Guardado del modelo
joblib.dump(mlp_model, "/content/drive/MyDrive/TFG/mlp_model_final1.pkl")

print("✅ Modelo MLP guardado como 'mlp_model_final1.pkl'")
