# -*- coding: utf-8 -*-
"""01_BrainLat_modelosConRESTMRI.ipynb

Automatically generated by Colab.

# 1. LECTURA DE DATOS, DESCARGA Y VISUALIZACIÓN.
"""

# Commented out IPython magic to ensure Python compatibility.
# %pip install --upgrade pysftp synapseclient python-dotenv
# %pip install --upgrade synapseclient
!pip install nibabel matplotlib numpy

!pip install --upgrade --force-reinstall numpy pandas

import os
import pandas as pd
from dotenv import load_dotenv
import synapseclient
import synapseutils

load_dotenv()
# Iniciamos sesión en Synapse
SYNAPSE_TOKEN = "token_censurado"
syn = synapseclient.Synapse()
syn.login(authToken=SYNAPSE_TOKEN)

# Leemos el CSV con los pacientes
filtered_df = pd.read_csv("directorio_censurado/BrainLat_Imputado2.csv", delimiter=";")
patient_ids = filtered_df["MRI_ID"].unique()

# Obtenemos la lista de archivos disponibles en Synapse
entity = syn.get('syn51549340', downloadFile=False)
file_list = list(synapseutils.walk(syn, entity.id))

# Descargamos solo los archivos que coincidan con los pacientes en MRI_ID
for dirpath, dirnames, filenames in file_list:
  for dir in dirpath:
    for filename in filenames:
      for patient_id in patient_ids:
        if patient_id in dir and "BrainLat_dataset_NewIDs" in dir:
          file_path = os.path.join('/Volumes/T7/BrainLat', dir[17:])

          try:
            syn.get(filename[1], downloadLocation=file_path)
            print(f"✅ Descargado: {filename[0]}")
          except Exception as e:
            print(f"❌ Error con {filename[0]}: {e}")

import nibabel as nib
import numpy as np
import matplotlib.pyplot as plt

# Ruta de la imagen
nii_path = "/Volumes/T7/BrainLat/MRI data/BrainLat_dataset_NewIDs/sub-COB086/func/sub-COB086_task-rest_bold.nii.gz"

img = nib.load(nii_path)

# Convertimos a array NumPy
data = img.get_fdata()

# Mostramos información
print(f"Dimensiones de la imagen: {data.shape}")
print(f"Tipo de datos: {data.dtype}")

# Seleccionamos un frame en el tiempo (por ejemplo, el primero)
timepoint = 0
data_3d = data[:, :, :, timepoint]  # Extraemos solo el volumen 3D de ese tiempo

slice_x = data_3d.shape[0] // 2  # Corte Sagital
slice_y = data_3d.shape[1] // 2  # Corte Coronal
slice_z = data_3d.shape[2] // 2  # Corte Axial

fig, axes = plt.subplots(1, 3, figsize=(15, 5))

# Corte Sagital (Vista lateral)
axes[0].imshow(data_3d[slice_x, :, :], cmap="gray", origin="lower")
axes[0].set_title("Corte Sagital (Lateral)")

# Corte Coronal (Vista frontal)
axes[1].imshow(data_3d[:, slice_y, :], cmap="gray", origin="lower")
axes[1].set_title("Corte Coronal (Frontal)")

# Corte Axial (Vista superior/inferior)
axes[2].imshow(data_3d[:, :, slice_z], cmap="gray", origin="lower")
axes[2].set_title("Corte Axial (Superior)")

for ax in axes:
    ax.axis("off")

plt.show()

# Mostramos misma imagen pero con colores
import matplotlib.pyplot as plt
import nibabel as nib

nii_file = "/Volumes/T7/BrainLat/MRI data/BrainLat_dataset_NewIDs/sub-COB086/func/sub-COB086_task-rest_bold.nii.gz"
img = nib.load(nii_file)
data = img.get_fdata()

timepoint = 0  # Podemos cambiarlo entre 0 y 119
data_3d = data[:, :, :, timepoint]

slice_x = data_3d.shape[0] // 2  # Corte Sagital
slice_y = data_3d.shape[1] // 2  # Corte Coronal
slice_z = data_3d.shape[2] // 2  # Corte Axial

fig, axes = plt.subplots(1, 3, figsize=(15, 5))
colormap = "jet"

# Corte Sagital (Vista lateral)
axes[0].imshow(data_3d[slice_x, :, :], cmap=colormap, origin="lower")
axes[0].set_title("Corte Sagital (Lateral)")

# Corte Coronal (Vista frontal)
axes[1].imshow(data_3d[:, slice_y, :], cmap=colormap, origin="lower")
axes[1].set_title("Corte Coronal (Frontal)")

# Corte Axial (Vista superior/inferior)
axes[2].imshow(data_3d[:, :, slice_z], cmap=colormap, origin="lower")
axes[2].set_title("Corte Axial (Superior)")

for ax in axes:
    ax.axis("off")

plt.show()

# Tanto data como data_3d son matrices de datos numéricos y el slice es la forma original de ese campo dividido entre 2
print(slice_z)
print(data_3d[slice_x, :, :])

"""# 2. PREPARACIÓN CONJUNTO DE DATOS.

"""

import nibabel as nib
import numpy as np
import pandas as pd
import os
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
import tensorflow as tf
from scipy.ndimage import zoom

base_path = "/Volumes/T7/BrainLat/MRI data/BrainLat_dataset_NewIDs"

# Función para verificar si existe la imagen de 'rest'
def imagen_existente(mri_id):
    image_path = os.path.join(base_path, mri_id, 'func', f"{mri_id}_task-rest_bold.nii.gz")
    return os.path.exists(image_path)

filtered_df["has_image"] = filtered_df["MRI_ID"].apply(imagen_existente)

# Nos quedamos solo con los que sí tienen imagen
filtered_df_with_image = filtered_df[filtered_df["has_image"] == True].copy()

X = []
y = []

label2id = {
    "AD": 0,
    "CN": 1,
    "PD": 2,
    "FTD": 3
}

TARGET_SHAPE = (64, 64, 40)

for i, row in filtered_df_with_image.iterrows():
  try:
    img_path = f"/Volumes/T7/BrainLat/MRI data/BrainLat_dataset_NewIDs/{row['MRI_ID']}/func/{row['MRI_ID']}_task-rest_bold.nii.gz"
    img = nib.load(img_path)
    data = img.get_fdata()

    timepoint = 0
    data_3d = data[:, :, :, timepoint]

    # Normalizamos
    data_3d = (data_3d - np.min(data_3d)) / (np.max(data_3d) - np.min(data_3d))

    zoom_factors = (
        TARGET_SHAPE[0] / data_3d.shape[0],
        TARGET_SHAPE[1] / data_3d.shape[1],
        TARGET_SHAPE[2] / data_3d.shape[2]
    )

    # Redimensionamos el volumen
    data_3d_resized = zoom(data_3d, zoom_factors)

    # Expandimos el canal
    data_3d_resized = np.expand_dims(data_3d_resized, axis=-1)

    X.append(data_3d_resized)
    y.append(label2id[row['diagnosis']])

  except Exception as e:
    print(f"Error procesando {img_path}: {e}")

X = np.array(X)
y = np.array(y)
print(X.shape)  # Se muestra: (n_samples, 64, 64, 40, 1)
print(y.shape)

# Mostramos X para el individuo 1 con forma (64 para eje X, 64 para eje Y, 40 para eje X), su imagen es un cubo 3D con todo valores numéricos
print(X[1])

# Examinamos las clases que restan para imágenes tipo Rest
conteo_diagnosticos = filtered_df_with_image['diagnosis'].value_counts()

print("Recuento de diagnósticos:")
print(conteo_diagnosticos)

"""# 3. PREPARACIÓN DE ETIQUETAS."""

# Codificamos etiquetas
encoder = LabelEncoder()
y_encoded = encoder.fit_transform(y)

X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded)

# Agregamos canal extra si falta
X_train = X_train[..., np.newaxis]
X_test = X_test[..., np.newaxis]

# Ahora AD:0, CN:1 y FTD:2
print(y_encoded)

"""# 4. DEFINICIÓN MODELO CNN."""

from tensorflow.keras import layers, models

num_classes = 4

model = models.Sequential([
    layers.Input(shape=(64, 64, 40, 1)),
    layers.Conv3D(32, (3, 3, 3), activation='relu'),
    layers.MaxPooling3D((2, 2, 2)),
    layers.Conv3D(64, (3, 3, 3), activation='relu'),
    layers.MaxPooling3D((2, 2, 2)),
    layers.Flatten(),
    layers.Dense(64, activation='relu'),
    layers.Dense(num_classes, activation='softmax')
])

model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])

model.summary()

"""# 5. ENTRENAMIENTO DEL MODELO.

Los epochs en una red convolucional (CNN) —o en cualquier red neuronal— representan cuántas veces el modelo pasa por todo el conjunto de entrenamiento.
- Si epoch = 1, no sería suficiente para aprender patrones complejos.
- Y si epoch es demasiado alto, podría haber un sobreajuste en el modelo.
"""

history = model.fit(X_train, y_train, epochs=20, batch_size=8, validation_split=0.2)

"""# 6. EVALUACIÓN DEL MODELO."""

test_loss, test_acc = model.evaluate(X_test, y_test)
print(f"Test Accuracy: {test_acc:.2f}")

from sklearn.metrics import classification_report
y_pred = model.predict(X_test).argmax(axis=1)
print(classification_report(y_test, y_pred))

"""Siendo 0 los individuos con alzheimer, 1 los sanos y 2 los que poseen demencia frontotemporal variante conductual.

# 7. GUARDADO DE LA RED NEURONAL CONVOLUCIONAL.
"""

# Con un accuracy de un 62% aproximadamente
model.save('/content/drive/MyDrive/TFG/CNN_model.keras')

"""# 8. CLUSTERING DE IMÁGENES.

## 8.1. Reducción de dimensionalidad + Clustering tradicional.
"""

from sklearn.decomposition import PCA
from sklearn.cluster import KMeans
from sklearn.manifold import TSNE
import numpy as np

# Aplanamos las imágenes: de (64, 64, 40) a (64*64*40 = 163840 features)
X_flatten = np.array([img.flatten() for img in X])
print(X_flatten)

"""Hemos aplanado los datos de imágenes 3D a vectores con 163840 features o valores para cada uno de los 184 individuos con imagen REST disponible."""

import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler

# Aplicamos PCA a los datos estandarizados con el fin de seleccionar el número de componentes principales óptimo
X_scaled = StandardScaler().fit_transform(X_flatten)

pca = PCA(n_components=50)
pca.fit(X_scaled)

# Varianza explicada por cada componente y valor promedio
explained_var = pca.explained_variance_ratio_ * 100
VPmedio = 100 / len(explained_var)

plt.figure(figsize=(8, 5))
plt.bar(range(1, len(explained_var) + 1), explained_var, alpha=0.7, label='Varianza explicada (%)')
plt.axhline(y=VPmedio, color='red', linestyle='--', label=f'Valor promedio ({VPmedio:.2f}%)')
plt.xlabel('Componente principal')
plt.ylabel('Porcentaje de varianza explicada')
plt.title('Scree plot (PCA)')
plt.legend()
plt.tight_layout()
plt.show()

# Reducimos dimensionalidad con PCA (el número de componentes principales óptimo es 9 o 10)
pca = PCA(n_components=10)
X_pca = pca.fit_transform(X_flatten)

# Clustering con K-Means
kmeans = KMeans(n_clusters=3, random_state=42)
clusters = kmeans.fit_predict(X_pca)

import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

# Visualización
X_tsne = TSNE(n_components=2).fit_transform(X_pca)
plt.figure(figsize=(8, 6))

cluster_colors = {0: 'blue', 1: 'red', 2: 'gold'}

# Color de fondo según clase real
for cluster_id in np.unique(clusters):
    idx = clusters == cluster_id
    plt.scatter(X_tsne[idx, 0], X_tsne[idx, 1],
                facecolors='none',
                edgecolors=cluster_colors[cluster_id],
                label=f'Cluster {cluster_id}',
                linewidths=1.5, s=80)

# Contornos según cluster asignado
for class_label in np.unique(y_encoded):
    idx = y_encoded == class_label
    plt.scatter(X_tsne[idx, 0], X_tsne[idx, 1],
                color=cluster_colors[class_label],
                label=f'Clase real {class_label}',
                alpha=0.6, edgecolors='k', linewidths=0.5)

plt.title('Clusters (contornos) vs Clases reales (colores)')
plt.xlabel('t-SNE 1')
plt.ylabel('t-SNE 2')
plt.legend()
plt.tight_layout()
plt.show()

"""Al menos los pacientes con alzheimer (azules) y demencia frontotemporal (amarillos) tienden a compartir una distribución bastante similar."""

# Evaluamos el resultado del clustering
from sklearn.metrics import adjusted_rand_score, silhouette_score

y_true = np.array(y_encoded)
print("Adjusted Rand Score:", adjusted_rand_score(y_true, clusters))
print("Silhouette Score:", silhouette_score(X_pca, clusters))

"""Estos resultados nos muestran que los datos por sí solos no son fácilmente separables, aunque un poco mejor que la aleatoria, este modelo sigue sin ser del todo adecuado.

## 8.2. Autoencoders para extraer características + Clustering.
"""

from tensorflow.keras.layers import Input, Conv3D, Flatten, Dense, Reshape, Conv3DTranspose
from tensorflow.keras.models import Model

# Definimos un autoencoder 3D
input_img = Input(shape=(64, 64, 40, 1))
x = Conv3D(32, (3, 3, 3), activation='relu', padding='same')(input_img)
x = Flatten()(x)
encoded = Dense(64, activation='relu')(x)

# Decoder
x = Dense(64 * 64 * 40 * 1, activation='relu')(encoded)
x = Reshape((64, 64, 40, 1))(x)
decoded = Conv3DTranspose(1, (3, 3, 3), activation='sigmoid', padding='same')(x)

# Modelo completo
autoencoder = Model(input_img, decoded)
autoencoder.compile(optimizer='adam', loss='mse')

# Entrenamos (usar X_train como entrada y salida)
autoencoder.fit(X_train, X_train, epochs=10, batch_size=16)

# Extraemos características del encoder
encoder = Model(input_img, encoded)
features = encoder.predict(X_train)

from sklearn.preprocessing import StandardScaler
from sklearn.cluster import DBSCAN

# Clustering con features normalizados (para que no haya ruido y cree más de un cluster)
features_scaled = StandardScaler().fit_transform(features)
clusters = DBSCAN(eps=0.8, min_samples=3).fit_predict(features_scaled)

# Evaluamos el resultado del clustering
y_true = y_train

print("Adjusted Rand Score (ARI):", adjusted_rand_score(y_true, clusters))
print("Silhouette Score:", silhouette_score(features, clusters))

"""## 8.3. Modelo preentrenado (ResNet)."""

!pip install monai

import torch
from monai.networks.nets import ResNet
import numpy as np

# Cargamos modelo preentrenado 3D
model = ResNet(
    block="basic",
    layers=[1, 1, 1, 1],
    block_inplanes = [64, 128, 256, 512],
    spatial_dims=3,      # Para 3D
    n_input_channels=1,
    num_classes=1,       # Solo extracción de features
    feed_forward=False
)

X_reshaped = np.transpose(X, (0, 4, 1, 2, 3))
X_tensor = torch.from_numpy(X_reshaped).float()

# Extraemos características
with torch.no_grad():
    features = model(X_tensor)

features = features.numpy()

from sklearn.cluster import DBSCAN

# Clustering
clusters = DBSCAN(eps=3.0, min_samples=3).fit_predict(features)

# Evaluamos el resultado del clustering
from sklearn.metrics import adjusted_rand_score, silhouette_score

y_true = y_encoded
print("Adjusted Rand Score (ARI):", adjusted_rand_score(y_true, clusters))
print("Silhouette Score:", silhouette_score(features, clusters))

"""1. Adjusted Rand Score (ARI) = 0.056

Casi 0: Los clusters generados son casi independientes de las etiquetas reales (AD, CN, PD, FTD).

Posible causa:

- Las características extraídas no son suficientemente discriminativas.

- Solapamiento entre patrones cerebrales de diferentes diagnósticos.

2. Silhouette Score = 0.23

Rango aceptable pero bajo: Los clusters tienen cierta cohesión interna, pero hay solapamiento entre ellos.

Valores de referencia:

- 0.5: Buena separación

- 0.2-0.5: Estructura débil

- < 0.2: Sin estructura clara

En definitiva, habrá que realizar unos reajustes o considerar más variables como tests cognitivos.

## 8.4. Red Neuronal Convolucional preentrenada perteneciente a Med3D (ResNet10).
"""

!pip install torch torchvision
!git clone https://github.com/Tencent/MedicalNet.git
!cd MedicalNet

# CARGA DEL MODELO RESNET10 3D PREENTRENADO
from monai.networks.nets import resnet10
import torch

model = resnet10(spatial_dims=3, n_input_channels=1, feed_forward=False, shortcut_type="B", bias_downsample=False, num_classes=3, pretrained=True)
model.eval()

# PREPROCESAMIENTO DE DATOS
import numpy as np
import torch

# X: (184, 64, 64, 40, 1) → (184, 1, 64, 64, 40)
X_tensor = torch.from_numpy(X).float().permute(0, 4, 1, 2, 3)

# Normalizamos a media 0 y desviación estándar 1
mean = X_tensor.mean()
std = X_tensor.std()
X_tensor = (X_tensor - mean) / std

# y_encoded: (184,) → tensor de etiquetas
y_tensor = torch.from_numpy(y_encoded).long()

# EXTRACCIÓN DE EMBEDDINGS CON MED3D
embeddings = []
with torch.no_grad():
    for x in X_tensor:
        x = x.unsqueeze(0)
        features = model.forward(x)
        embeddings.append(features.squeeze(0))

embeddings = torch.stack(embeddings)  # (184, embedding_dim)

# APLICACIÓN DE VALIDACIÓN CRUZADA
from sklearn.model_selection import StratifiedKFold, cross_val_score
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import StandardScaler

# Clasificador sobre los embeddings
clf = make_pipeline(
    StandardScaler(),
    LogisticRegression(max_iter=1000)
)

cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

scores = cross_val_score(clf, embeddings, y, cv=cv, scoring='accuracy')

print(f"Accuracies por fold: {scores}")
print(f"Media accuracy: {scores.mean():.4f}")
print(f"Desviación estándar: {scores.std():.4f}")

# CLASIFICACIÓN Y EVALUACIÓN
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report

# Convertimos a numpy
X_emb = embeddings.numpy()
y = y_tensor.numpy()

X_train, X_test, y_train, y_test = train_test_split(X_emb, y, test_size=0.2, random_state=42, stratify=y)
print(X_emb)

# Entrenamos clasificador simple: regresión logística
clf = LogisticRegression(max_iter=1000, class_weight='balanced') # Aplicamos técnica de balanceado
clf.fit(X_train, y_train)

# Evaluamos
y_pred = clf.predict(X_test)
print(classification_report(y_test, y_pred))

"""Teniendo en cuenta el resultado del f1-score, las tres clases parecen tener un rendimiento decente, aunque no bueno, más bien inclinándose a malo. Pero esto podría mejorar mil veces si se añaden variables demográficas y de tests cognitivos."""

# VISUALIZACIÓN
from sklearn.manifold import TSNE
import matplotlib.pyplot as plt

tsne = TSNE(n_components=2, random_state=42)
X_tsne = tsne.fit_transform(X_emb)

plt.figure(figsize=(8, 6))
for label in np.unique(y):
    idx = y == label
    plt.scatter(X_tsne[idx, 0], X_tsne[idx, 1], label=f'Clase {label}')
plt.legend()
plt.title('Visualización de embeddings con t-SNE')
plt.xlabel('Componente 1')
plt.ylabel('Componente 2')
plt.show()

# PROBAMOS CON RANDOM FOREST
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report
from sklearn.model_selection import train_test_split

# Dividimos datos con estratificación para mantener balance de clases
X_train, X_test, y_train, y_test = train_test_split(X_emb, y, test_size=0.2, random_state=42, stratify=y)

rf_clf = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')
rf_clf.fit(X_train, y_train)

# Predicciones y evaluación
y_pred_rf = rf_clf.predict(X_test)
print(classification_report(y_test, y_pred_rf, zero_division=0))

"""Con Random Forest la clasificación va mejorando."""

# PROBAMOS A DEJAR LA CLASIFICACIÓN SUPERVISADA DE LADO Y A APLICAR CLUSTERING
from sklearn.cluster import KMeans
from sklearn.metrics import adjusted_rand_score, silhouette_score

kmeans = KMeans(n_clusters=3, random_state=42)
clusters = kmeans.fit_predict(X_emb)

from sklearn.metrics import classification_report

ari = adjusted_rand_score(y, clusters)
silhouette = silhouette_score(X_emb, clusters)

print(f"Adjusted Rand Index (ARI): {ari:.4f}")
print(f"Silhouette Score: {silhouette:.4f}")

"""Con este modelo neuronal convolucional perteneciente al repositorio Med3D el clustering parece mejorar bastante."""

from sklearn.manifold import TSNE
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

# Visualización
X_tsne = TSNE(n_components=2, random_state=42).fit_transform(X_emb)
plt.figure(figsize=(8, 6))

cluster_colors = {0: 'blue', 1: 'red', 2: 'gold'}

# Color de fondo según clase real
for cluster_id in np.unique(clusters):
    idx = clusters == cluster_id
    plt.scatter(X_tsne[idx, 0], X_tsne[idx, 1],
                facecolors='none',
                edgecolors=cluster_colors[cluster_id],
                label=f'Cluster {cluster_id}',
                linewidths=1.5, s=80)

# Contornos según cluster asignado
for class_label in np.unique(y_encoded):
    idx = y_encoded == class_label
    plt.scatter(X_tsne[idx, 0], X_tsne[idx, 1],
                color=cluster_colors[class_label],
                label=f'Clase real {class_label}',
                alpha=0.6, edgecolors='k', linewidths=0.5)

plt.title('Clusters (contornos) vs Clases reales (colores)')
plt.xlabel('t-SNE 1')
plt.ylabel('t-SNE 2')
plt.legend()
plt.tight_layout()
plt.show()

"""## 8.5. Red Neuronal Convolucional profunda (DenseNet121)."""

!pip install -q monai torchio

import torch
import numpy as np
from monai.networks.nets import DenseNet121
from sklearn.model_selection import cross_val_score, StratifiedKFold
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import StandardScaler

# Simulación: X debe ser un numpy array de (184, 64, 64, 40, 1)
X_tensor = torch.from_numpy(X).float().permute(0, 4, 1, 2, 3)  # → (184, 1, 64, 64, 40)

X_tensor = (X_tensor - X_tensor.mean()) / X_tensor.std()

model = DenseNet121(spatial_dims=3, in_channels=1, out_channels=3)
model.eval()

# Pasamos los datos por la red para obtener embeddings
embeddings = []
with torch.no_grad():
    for i in range(X_tensor.shape[0]):
        x = X_tensor[i].unsqueeze(0)  # (1, 1, 64, 64, 40)
        feats = model.features(x)     # usamos los "features" previos a la última capa
        pooled = torch.nn.functional.adaptive_avg_pool3d(feats, (1, 1, 1)).squeeze()
        embeddings.append(pooled)

embeddings = torch.stack(embeddings).numpy()

# Clasificamos con validación cruzada
clf = make_pipeline(StandardScaler(), LogisticRegression(max_iter=1000))
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
scores = cross_val_score(clf, embeddings, y_encoded, cv=cv, scoring='accuracy')

print(f"Accuracy media: {scores.mean():.4f} ± {scores.std():.4f}")
