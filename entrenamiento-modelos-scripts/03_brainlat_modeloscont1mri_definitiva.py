# -*- coding: utf-8 -*-
"""03_BrainLat_modelosConT1MRI_Definitiva.ipynb

Automatically generated by Colab.

# 1. LECTURA DE DATOS, DESCARGA Y VISUALIZACIÓN.
"""

# Commented out IPython magic to ensure Python compatibility.
# %pip install --upgrade pysftp synapseclient python-dotenv
# %pip install --upgrade synapseclient
!pip install nibabel matplotlib numpy
!pip install pyradiomics SimpleITK
!pip uninstall -y tensorflow
!pip install tensorflow==2.12.0
!pip install monai
!pip install torch torchvision
!git clone https://github.com/Tencent/MedicalNet.git
!cd MedicalNet
!pip install -q monai torchio

import os
import pandas as pd
from dotenv import load_dotenv
import synapseclient
import synapseutils
import nibabel as nib
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
import tensorflow as tf
from scipy.ndimage import zoom
from google.colab import drive
drive.mount('/content/drive')

# Leemos el CSV con los pacientes
filtered_df = pd.read_csv("directorio_censurado/BrainLat_Imputado3.csv", delimiter=";")
patient_ids = filtered_df["MRI_ID"].unique()

import os
import pandas as pd
from dotenv import load_dotenv
import synapseclient
import synapseutils

load_dotenv()
# Iniciamos sesión en Synapse
SYNAPSE_TOKEN = "token_censurado"
syn = synapseclient.Synapse()
syn.login(authToken=SYNAPSE_TOKEN)

# Leemos el CSV con los pacientes
filtered_df = pd.read_csv("directorio_censurado/BrainLat_Imputado3.csv", delimiter=";")
patient_ids = filtered_df["MRI_ID"].unique()

# Obtenemos la lista de archivos disponibles en Synapse
entity = syn.get('syn51549340', downloadFile=False)
file_list = list(synapseutils.walk(syn, entity.id))

# Descargamos solo los archivos que coincidan con los pacientes en MRI_ID
for dirpath, dirnames, filenames in file_list:
  for dir in dirpath:
    for filename in filenames:
      for patient_id in patient_ids:
        if patient_id in dir and "BrainLat_dataset_NewIDs" in dir:
          file_path = os.path.join('/Volumes/T7/BrainLat', dir[17:])
          try:
            syn.get(filename[1], downloadLocation=file_path)
            print(f"✅ Descargado: {filename[0]}")
          except Exception as e:
            print(f"❌ Error con {filename[0]}: {e}")

import nibabel as nib
import numpy as np
import matplotlib.pyplot as plt

# Ruta de la imagen
nii_path = "/Volumes/T7/BrainLat/MRI data/BrainLat_dataset_NewIDs/sub-COB086/anat/sub-COB086_T1w.nii.gz"

img = nib.load(nii_path)

# Convertimos a array NumPy
data = img.get_fdata()

# Mostramos información
print(f"Dimensiones de la imagen: {data.shape}")
print(f"Tipo de datos: {data.dtype}")

data_3d = data[:, :, :]  # Extraemos el volumen 3D

slice_x = data_3d.shape[0] // 2  # Corte Sagital
slice_y = data_3d.shape[1] // 2  # Corte Coronal
slice_z = data_3d.shape[2] // 2  # Corte Axial

fig, axes = plt.subplots(1, 3, figsize=(15, 5))

# Corte Coronal (Vista frontal)
axes[0].imshow(data_3d[slice_x, :, :], cmap="gray", origin="lower")
axes[0].set_title("Corte Coronal (Frontal)")

# Corte Axial (Vista superior/inferior)
axes[1].imshow(data_3d[:, slice_y, :], cmap="gray", origin="lower")
axes[1].set_title("Corte Axial (Superior)")

# Corte Sagital (Vista lateral)
axes[2].imshow(data_3d[:, :, slice_z], cmap="gray", origin="lower")
axes[2].set_title("Corte Sagital (Lateral)")

for ax in axes:
    ax.axis("off")

plt.show()

# Mostramos misma imagen pero con colores
import matplotlib.pyplot as plt
import nibabel as nib

slice_x = data_3d.shape[0] // 2  # Corte Sagital
slice_y = data_3d.shape[1] // 2  # Corte Coronal
slice_z = data_3d.shape[2] // 2  # Corte Axial

fig, axes = plt.subplots(1, 3, figsize=(15, 5))
colormap = "jet"

# Corte Coronal (Vista frontal)
axes[0].imshow(data_3d[slice_x, :, :], cmap=colormap, origin="lower")
axes[0].set_title("Corte Coronal (Frontal)")

# Corte Axial (Vista superior/inferior)
axes[1].imshow(data_3d[:, slice_y, :], cmap=colormap, origin="lower")
axes[1].set_title("Corte Axial (Superior)")

# Corte Sagital (Vista lateral)
axes[2].imshow(data_3d[:, :, slice_z], cmap=colormap, origin="lower")
axes[2].set_title("Corte Sagital (Lateral)")

for ax in axes:
    ax.axis("off")

plt.show()

# Tanto data como data_3d son matrices de datos numéricos y el slice es la forma original de ese campo dividido entre 2
print(slice_z)
print(data_3d[slice_x, :, :])

"""# 2. PREPARACIÓN CONJUNTO DE DATOS.

"""

import nibabel as nib
import numpy as np
import pandas as pd
import os
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
import tensorflow as tf
from scipy.ndimage import zoom

base_path = "/Volumes/T7/BrainLat/MRI data/BrainLat_dataset_NewIDs"

# Función para verificar si existe la imagen de 'T1'
def imagen_existente(mri_id):
    image_path = os.path.join(base_path, mri_id, 'anat', f"{mri_id}_T1w.nii.gz")
    return os.path.exists(image_path)

filtered_df["has_image"] = filtered_df["MRI_ID"].apply(imagen_existente)

# Nos quedamos solo con los que sí tienen imagen
filtered_df_with_image = filtered_df[filtered_df["has_image"] == True].copy()

label2id = {
    "AD": 0,
    "CN": 1,
    "PD": 2,
    "FTD": 3
}

TARGET_SHAPE = (64, 64, 40)

X = []
y = []
mri_ids = []

for i, row in filtered_df_with_image.iterrows():
    try:
        img_path = f"/Volumes/T7/BrainLat/MRI data/BrainLat_dataset_NewIDs/{row['MRI_ID']}/anat/{row['MRI_ID']}_T1w.nii.gz"
        img = nib.load(img_path)
        data = img.get_fdata()
        data_3d = data[:, :, :]
        # Para ocupar menos lugar
        data_3d = data_3d.astype(np.float32)

        # Normalizamos
        data_3d = (data_3d - np.mean(data_3d)) / np.std(data_3d)

        zoom_factors = (
            TARGET_SHAPE[0] / data_3d.shape[0],
            TARGET_SHAPE[1] / data_3d.shape[1],
            TARGET_SHAPE[2] / data_3d.shape[2]
        )

        # Redimensionamos el volumen
        data_3d_resized = zoom(data_3d, zoom_factors)

        # Expandimos el canal
        data_3d_resized = np.expand_dims(data_3d_resized, axis=-1)

        X.append(data_3d_resized)
        y.append(label2id[row['diagnosis']])
        mri_ids.append(row['MRI_ID'])  # Añadimos solo si se pudo procesar

    except Exception as e:
        print(f"Error procesando {row['MRI_ID']} ({row['diagnosis']}): {e}")

X = np.array(X)
y = np.array(y, dtype=np.int32)
mri_ids = np.array(mri_ids)
print(X.shape)  # Se muestra: (n_samples, 64, 64, 40, 1)
print(y.shape)

# Mostramos X para el individuo 1 con forma (64 para eje X, 64 para eje Y, 40 para eje X), su imagen es un cubo 3D con todo valores numéricos
print(X[1])

# Examinamos las clases que restan para imágenes tipo T1
conteo_diagnosticos = filtered_df_with_image['diagnosis'].value_counts()

print("Recuento de diagnósticos:")
print(conteo_diagnosticos)

"""# 3. PREPARACIÓN DE ETIQUETAS."""

# Codificamos etiquetas
encoder = LabelEncoder()
y_encoded = encoder.fit_transform(y)

# Ahora AD:0, CN:1 y FTD:2
print(y_encoded)

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test, train_ids, test_ids = train_test_split(X, y_encoded, mri_ids, test_size=0.2, stratify=y_encoded, random_state=42)

# Guardado
#from google.colab import drive
#drive.mount('/content/drive')

#np.savez_compressed("/content/drive/MyDrive/TFG/train_data.npz", X=X_train, y=y_train, ids=train_ids)
#np.savez_compressed("/content/drive/MyDrive/TFG/test_data.npz", X=X_test, y=y_test, ids=test_ids)

# Carga
# from google.colab import drive
# drive.mount('/content/drive')

train = np.load("/content/drive/MyDrive/TFG/train_data.npz", allow_pickle=True)
X_train = train["X"]
y_train = train["y"]
train_ids = train["ids"].astype(str)  # <-- 100% alineado: X_train[i] corresponde a y_train[i] y a train_ids[i], mismo orden

test = np.load("/content/drive/MyDrive/TFG/test_data.npz", allow_pickle=True)
X_test = test["X"]
y_test = test["y"]
test_ids = test["ids"].astype(str)

print(train)

# Carga y división variables demográficas
import pandas as pd
import numpy as np

df = pd.read_csv("/content/drive/MyDrive/TFG/BrainLat_Imputado3.csv", delimiter=";")
df["MRI_ID"] = df["MRI_ID"].astype(str)

# Filtramos únicamente los MRI_IDs presentes en los datos de imagen
filtered_df = df[df["MRI_ID"].isin(np.concatenate([train_ids, test_ids]))].copy()

# Dividimos en conjuntos train y test manteniendo el orden
df_train = filtered_df.set_index("MRI_ID").loc[train_ids].reset_index()
df_test = filtered_df.set_index("MRI_ID").loc[test_ids].reset_index()

df_train.shape, df_test.shape

df_train.head()

"""# 4. SELECCIÓN DE EMBEDDINGS PARA MRIs T1.

## 4.1. TIPO A: CNN Feature Extractor.
"""

from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Conv3D, MaxPooling3D, Flatten, Dense

input_layer = Input(shape=(64, 64, 40, 1))
x = Conv3D(16, (3, 3, 3), activation='relu', padding='same')(input_layer)
x = MaxPooling3D((2, 2, 2))(x)
x = Conv3D(32, (3, 3, 3), activation='relu', padding='same')(x) # Conv3D + MaxPooling3D: buena combinación para datos volumétricos como resonancias T1
x = MaxPooling3D((2, 2, 2))(x)
x = Flatten()(x)
x = Dense(128, activation='relu')(x)  # Este será nuestro embedding

# No sobreajustamos con redes gigantes innecesarias en datasets médicos pequeños
# Modelo extractor
cnn_model1 = Model(inputs=input_layer, outputs=x)

# Versión con posibles mejoras
from tensorflow.keras.layers import Input, Conv3D, MaxPooling3D, GlobalAveragePooling3D, Dense, BatchNormalization, Activation
from tensorflow.keras.models import Model

input_layer = Input(shape=(64, 64, 40, 1))
x = Conv3D(32, (3, 3, 3), padding='same')(input_layer)
x = BatchNormalization()(x)
x = Activation('relu')(x)
x = MaxPooling3D((2, 2, 2))(x)

x = Conv3D(64, (3, 3, 3), padding='same')(x)
x = BatchNormalization()(x)
x = Activation('relu')(x)
x = MaxPooling3D((2, 2, 2))(x)

x = GlobalAveragePooling3D()(x)
embedding = Dense(128, activation='relu')(x)

cnn_model2 = Model(inputs=input_layer, outputs=embedding)

embeddings_cnn1 = cnn_model1.predict(X_train, batch_size=16)
embeddings_cnn2 = cnn_model2.predict(X_train, batch_size=16)

"""## 4.2. TIPO B: PCA."""

from sklearn.decomposition import PCA
import matplotlib.pyplot as plt
import numpy as np

# Aplanamos primero: (n_samples, 64*64*40)
X_flat = X_train.reshape((X_train.shape[0], -1))

# Aplicamos PCA sin limitar componentes
pca_full = PCA().fit(X_flat)

# Varianza acumulada
cum_var_exp = np.cumsum(pca_full.explained_variance_ratio_)

# Elegimos el número de componentes que explica al menos el 95% de la varianza
n_components_optimo = np.argmax(cum_var_exp >= 0.95) + 1

# Graficamos
plt.figure(figsize=(8, 4))
plt.plot(cum_var_exp, marker='o')
plt.axhline(0.95, color='r', linestyle='--')
plt.axvline(n_components_optimo, color='g', linestyle='--')
plt.title("Varianza explicada acumulada")
plt.xlabel("Número de componentes")
plt.ylabel("Varianza acumulada")
plt.grid(True)
plt.show()

print(f"Número óptimo de componentes (≥95% varianza): {n_components_optimo}")

pca = PCA(n_components=207)
embeddings_pca = pca.fit_transform(X_flat)

"""## 4.3. TIPO C: Autoencoder."""

from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Conv3D, MaxPooling3D, UpSampling3D

input_layer = Input(shape=(64, 64, 40, 1))
x = Conv3D(16, (3, 3, 3), activation='relu', padding='same')(input_layer)
x = MaxPooling3D((2, 2, 2), padding='same')(x)
x = Conv3D(8, (3, 3, 3), activation='relu', padding='same')(x)
encoded = MaxPooling3D((2, 2, 2), padding='same')(x)

# Decoder
x = Conv3D(8, (3, 3, 3), activation='relu', padding='same')(encoded)
x = UpSampling3D((2, 2, 2))(x)
x = Conv3D(16, (3, 3, 3), activation='relu')(x)
x = UpSampling3D((2, 2, 2))(x)
decoded = Conv3D(1, (3, 3, 3), activation='sigmoid', padding='same')(x)

autoencoder = Model(input_layer, decoded)
encoder_model = Model(inputs=input_layer, outputs=encoded)

embeddings_ae = encoder_model.predict(X_train)
embeddings_ae_flat = embeddings_ae.reshape((X_train.shape[0], -1))

"""## 4.4. Aspecto embeddings."""

print("Aspecto embedding con CNN: ", embeddings_cnn1)
print("Aspecto embedding con PCA: ", embeddings_pca)
print("Aspecto embedding con Autoencoder flat: ", embeddings_ae_flat)

"""# 5. ENTRENAMIENTO DE MODELOS.

## 5.1. BLOQUE A: Tests cognitivos + variables demográficas.
"""

import pandas as pd
import numpy as np
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.neural_network import MLPClassifier
from sklearn.cross_decomposition import PLSRegression
from sklearn.metrics import accuracy_score, f1_score, classification_report
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import train_test_split
from imblearn.pipeline import Pipeline
from imblearn.over_sampling import SMOTE
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder
from sklearn.base import BaseEstimator, ClassifierMixin

# CLASE ENVOLTORIO PARA PLS-DA (PLS + LDA)
class PLS_DA(BaseEstimator, ClassifierMixin):
    def __init__(self, n_components=2):
        self.n_components = n_components
        self.pls = PLSRegression(n_components=n_components)
        self.clf = LinearDiscriminantAnalysis()

    def fit(self, X, y):
        self.pls.fit(X, y)
        X_pls = self.pls.transform(X)
        self.clf.fit(X_pls, y)
        return self

    def predict(self, X):
        X_pls = self.pls.transform(X)
        return self.clf.predict(X_pls)

# 1. Variables del Bloque A
demograficas = ["sex", "Age", "years_education", "laterality", "country", "center"]
cognitivos = [
    "ifs_total_score", "ifs_motor_series", "ifs_conflicting_instructions",
    "ifs_motor_inhibition", "ifs_digits", "ifs_months", "ifs_visual_wm",
    "ifs_proverb", "ifs_verbal_inhibition", "mini_sea_fer", "mini_sea_tom"
]
df_cols = demograficas + cognitivos

# 2. Selección columnas
df_y_train = df_train["diagnosis"].map({
    "AD": 0,
    "CN": 1,
    "FTD": 2
})
df_y_test = df_test["diagnosis"].map({
    "AD": 0,
    "CN": 1,
    "FTD": 2
})
df_train_bloqueA = df_train[df_cols]
df_test_bloqueA = df_test[df_cols]

# 3. Preprocesamiento
categorical_cols = ["sex", "laterality", "country", "center"]
numerical_cols = ["Age", "years_education"] + cognitivos

preprocessor = ColumnTransformer([
    ("num", StandardScaler(), numerical_cols),
    ("cat", OneHotEncoder(drop='first'), categorical_cols)
])

# 4. Modelos
modelos = {
    "Random Forest": RandomForestClassifier(n_estimators=100, random_state=42),
    "SVM": SVC(kernel='linear', probability=True),
    "LDA": LinearDiscriminantAnalysis(),
    "MLP (NN)": MLPClassifier(hidden_layer_sizes=(64,), max_iter=500, random_state=42),
    "PLS-DA": PLS_DA(n_components=4)
}

# 5. Entrenamiento y evaluación
for nombre, modelo in modelos.items():
    # Aplicamos oversampling con smote para el balanceo de datos
    pipeline = Pipeline([
        ("preproc", preprocessor),
        ("smote", SMOTE(random_state=42)),
        ("clf", modelo)
    ])
    pipeline.fit(df_train_bloqueA, df_y_train)
    y_pred = pipeline.predict(df_test_bloqueA)

    acc = accuracy_score(df_y_test, y_pred)
    f1 = f1_score(df_y_test, y_pred, average="weighted")

    print(f"\n=== {nombre} ===")
    print(f"Accuracy: {acc:.4f}")
    print(f"F1-score: {f1:.4f}")
    print(classification_report(df_y_test, y_pred))

import pandas as pd

# Tabla con resultados bloque A
data = {
    "Modelo": ["Random Forest", "SVM", "LDA", "MLP (NN)", "PLS-DA"],
    "Accuracy": [0.8361, 0.8197, 0.8033, 0.8197, 0.7869],
    "F1-score": [0.8296, 0.8185, 0.7983, 0.8165, 0.7857]
}

tabla_resumen = pd.DataFrame(data)

print("=== Tabla resumen de desempeño por modelo bloque A ===")
print(tabla_resumen.to_string(index=False))

"""## 5.2. BLOQUE B: Embeddings A, B y C.

"""

import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.neural_network import MLPClassifier
from sklearn.cross_decomposition import PLSRegression
from sklearn.metrics import accuracy_score, f1_score, classification_report
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from imblearn.over_sampling import SMOTE
from sklearn.base import BaseEstimator, ClassifierMixin

# CLASE PARA PLS-DA
class PLS_DA(BaseEstimator, ClassifierMixin):
    def __init__(self, n_components=5):
        self.n_components = n_components
        self.pls = PLSRegression(n_components=n_components)
        self.clf = LinearDiscriminantAnalysis()

    def fit(self, X, y):
        self.pls.fit(X, y)
        X_pls = self.pls.transform(X)
        self.clf.fit(X_pls, y)
        return self

    def predict(self, X):
        X_pls = self.pls.transform(X)
        return self.clf.predict(X_pls)

# 1. Carga de datos
train = np.load("/content/drive/MyDrive/TFG/train_data.npz", allow_pickle=True)
X_train = train["X"]
y_train = train["y"]
train_ids = train["ids"]

test = np.load("/content/drive/MyDrive/TFG/test_data.npz", allow_pickle=True)
X_test = test["X"]
y_test = test["y"]
test_ids = test["ids"]

embeddings_cnn1_train = embeddings_cnn1
embeddings_cnn2_train = embeddings_cnn2
embeddings_cnn1_test = cnn_model1.predict(X_test, batch_size=16)
embeddings_cnn2_test = cnn_model2.predict(X_test, batch_size=16)

embeddings_pca_train = embeddings_pca
X_test_flat = X_test.reshape((X_test.shape[0], -1))
embeddings_pca_test = pca.transform(X_test_flat)

embeddings_ae_flat_train = embeddings_ae_flat
embeddings_ae_test = encoder_model.predict(X_test)
embeddings_ae_flat_test = embeddings_ae_test.reshape((X_test.shape[0], -1))

# 2. Escalado global
scaler = StandardScaler()
X_trainA1 = scaler.fit_transform(embeddings_cnn1_train)
X_testA1 = scaler.transform(embeddings_cnn1_test)
scaler2 = StandardScaler()
X_trainA2 = scaler2.fit_transform(embeddings_cnn2_train)
X_testA2 = scaler2.transform(embeddings_cnn2_test)

scaler3 = StandardScaler()
X_trainB = scaler3.fit_transform(embeddings_pca_train)
X_testB = scaler3.transform(embeddings_pca_test)

scaler4 = StandardScaler()
X_trainC = scaler4.fit_transform(embeddings_ae_flat_train)
X_testC = scaler4.transform(embeddings_ae_flat_test)

# 3. Modelos a comparar
modelos = {
    "Random Forest": RandomForestClassifier(n_estimators=100, random_state=42),
    "SVM": SVC(kernel='linear', probability=True),
    "LDA": LinearDiscriminantAnalysis(),
    "MLP (NN)": MLPClassifier(hidden_layer_sizes=(64,), max_iter=500, random_state=42),
    "PLS-DA": PLS_DA(n_components=5)
}

# 4. Entrenamiento y evaluación
embeddings_datasets = {
    "CNN1": (X_trainA1, X_testA1),
    "CNN2": (X_trainA2, X_testA2),
    "PCA": (X_trainB, X_testB),
    "Autoencoder": (X_trainC, X_testC)
}
for emb,conj in embeddings_datasets.items():
  print(f"{emb}")
  # Aplicamos oversampling solo a las muestras de entrenamiento
  smote = SMOTE(random_state=42)
  X_train_balanced, y_train_balanced = smote.fit_resample(conj[0], y_train)
  for nombre, modelo in modelos.items():
      modelo.fit(X_train_balanced, y_train_balanced)
      y_pred = modelo.predict(conj[1])

      acc = accuracy_score(y_test, y_pred)
      f1 = f1_score(y_test, y_pred, average="weighted")

      print(f"\n=== {nombre} ===")
      print(f"Accuracy: {acc:.4f}")
      print(f"F1-score: {f1:.4f}")
      print(classification_report(y_test, y_pred))

import pandas as pd

# Tabla con los mejores resultados
data = {
    "Embedding": ["CNN1", "CNN2", "PCA", "Autoencoder"],
    "Mejor Modelo": ["PLS-DA", "MLP (NN)", "SVM", "Random Forest"],
    "Accuracy": [0.7049, 0.7049, 0.7213, 0.7541],
    "F1-score": [0.7030, 0.7031, 0.7153, 0.7427]
}

tabla_resumen = pd.DataFrame(data)

print("=== Tabla resumen de desempeño por embedding ===")
print(tabla_resumen.to_string(index=False))

"""El mejor embedding parece ser Autoencoder en principio, seguido de cerca por PCA y luego CNN2, porque:

- Autoencoder es una buena opción si quieres preservar una representación no lineal, aunque ligeramente inferior.

- PCA es muy competitivo y puede ser preferido si se busca interpretabilidad.

- CNN2 con MLP ofrece el mejor equilibrio entre clases, mayor robustez y F1 más alto.
"""

# Aplicamos cross validation porque resulta sospechoso que el mejor embedding sea el obtenido con Autoencoder siendo que:
# - Las redes neuronales convolucionales son las mejores para sacar features de imágenes.
# - CNN2 es una red convolucional con mejoras introducidas.
import numpy as np
import pandas as pd
from sklearn.model_selection import cross_val_score, StratifiedKFold
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.neural_network import MLPClassifier
from sklearn.preprocessing import StandardScaler

# Escalamos los embeddings
scaler = StandardScaler()
cnn1 = scaler.fit_transform(embeddings_cnn1_train)
cnn2 = scaler.fit_transform(embeddings_cnn2_train)
pca  = scaler.fit_transform(embeddings_pca_train)
ae   = scaler.fit_transform(embeddings_ae_flat_train)

# Diccionario con mejores modelos por embedding
mejores_modelos = {
    "CNN1": (cnn1, RandomForestClassifier(n_estimators=100, random_state=42)),
    "CNN2": (cnn2, RandomForestClassifier(n_estimators=100, random_state=42)),
    "PCA":  (pca,  SVC(kernel='linear')),
    "Autoencoder": (ae, RandomForestClassifier(n_estimators=100, random_state=42))
}

# Cross-validation
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

resultados_cv = []
for nombre, (X, modelo) in mejores_modelos.items():
    acc_scores = cross_val_score(modelo, X, y_train, cv=cv, scoring='accuracy')
    f1_scores = cross_val_score(modelo, X, y_train, cv=cv, scoring='f1_weighted')

    resultados_cv.append({
        "Embedding": nombre,
        "Mejor Modelo": type(modelo).__name__,
        "Accuracy (CV)": np.mean(acc_scores),
        "F1-score (CV)": np.mean(f1_scores)
    })

# Creamos DataFrame resumen
tabla_cv = pd.DataFrame(resultados_cv)
print("=== Resultados con Validación Cruzada (5-Fold) ===")
print(tabla_cv.to_string(index=False))

"""Finalmente, la mejor opción para obtener embeddings sería CNN con diferencia con Random Forest. Se hará uso de este embedding en el entrenamiento de los datos que constituyen el bloque C.

## 5.3. BLOQUE C: Tests cognitivos + variables demográficas + mejor embedding.
"""

import numpy as np
import pandas as pd
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer

# 1. Datos preparados bloque A
# df_train_bloqueA
# df_test_bloqueA

# 2. Preprocesamiento
preprocessor = ColumnTransformer([
    ("num", StandardScaler(), numerical_cols),
    ("cat", OneHotEncoder(drop='first'), categorical_cols)
])

df_trainA_proc = preprocessor.fit_transform(df_train_bloqueA)
df_testA_proc = preprocessor.transform(df_test_bloqueA)

# 3. Concatenación
X_train_concat = np.concatenate([df_trainA_proc, embeddings_cnn2_train], axis=1)
X_test_concat = np.concatenate([df_testA_proc, embeddings_cnn2_test], axis=1)

print(df_trainA_proc[1]) # 13 numéricas escaladas, 2 binarias y 2 categóricas a las que se les aplica el one-hot encoding

import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.neural_network import MLPClassifier
from sklearn.cross_decomposition import PLSRegression
from sklearn.metrics import accuracy_score, f1_score, classification_report
from sklearn.preprocessing import StandardScaler
from sklearn.base import BaseEstimator, ClassifierMixin
from imblearn.over_sampling import SMOTE

# Clase para PLS-DA
class PLS_DA(BaseEstimator, ClassifierMixin):
    def __init__(self, n_components=5):
        self.n_components = n_components
        self.pls = PLSRegression(n_components=n_components)
        self.clf = LinearDiscriminantAnalysis()

    def fit(self, X, y):
        self.pls.fit(X, y)
        X_pls = self.pls.transform(X)
        self.clf.fit(X_pls, y)
        return self

    def predict(self, X):
        X_pls = self.pls.transform(X)
        return self.clf.predict(X_pls)

# Normalización de los datos combinados
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train_concat)
X_test_scaled = scaler.transform(X_test_concat)

# Modelos a evaluar
modelos = {
    "Random Forest": RandomForestClassifier(n_estimators=100, random_state=42),
    "SVM (Linear)": SVC(kernel='linear', probability=True),
    "LDA": LinearDiscriminantAnalysis(),
    "MLP (NN)": MLPClassifier(hidden_layer_sizes=(64,), max_iter=500, random_state=42),
    "PLS-DA": PLS_DA(n_components=5)
}

# Entrenamiento y evaluación
resultados = []

# Aplicamos oversampling solo a las muestras de entrenamiento
smote = SMOTE(random_state=42)
X_train_scaled_balanced, y_train_balanced = smote.fit_resample(X_train_scaled, y_train)

for nombre, modelo in modelos.items():
    modelo.fit(X_train_scaled_balanced, y_train_balanced)
    y_pred = modelo.predict(X_test_scaled)

    acc = accuracy_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred, average="weighted")

    print(f"\n=== {nombre} ===")
    print(f"Accuracy: {acc:.4f}")
    print(f"F1-score: {f1:.4f}")
    print(classification_report(y_test, y_pred))

    resultados.append({
        "Modelo": nombre,
        "Accuracy": acc,
        "F1-score": f1
    })

# Mostrar resultados en tabla
df_resultados = pd.DataFrame(resultados)
print("\nResumen comparativo:")
print(df_resultados)

"""¿Por qué ha funcionado tan bien el Random Forest?

## 5.4. CNN2: Clasificación MRIs ponderadas en T1.
"""

import numpy as np
from tensorflow.keras.layers import Input, Conv3D, MaxPooling3D, GlobalAveragePooling3D, Dense, BatchNormalization, Activation
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.utils import to_categorical
from sklearn.metrics import classification_report, accuracy_score, f1_score
from tensorflow.keras.callbacks import EarlyStopping

# Carga de datos
train = np.load("/content/drive/MyDrive/TFG/train_data.npz", allow_pickle=True)
X_train = train["X"]
y_train = train["y"]
train_ids = train["ids"].astype(str)

test = np.load("/content/drive/MyDrive/TFG/test_data.npz", allow_pickle=True)
X_test = test["X"]
y_test = test["y"]
test_ids = test["ids"].astype(str)

# Aseguramos forma y tipo
X_train = X_train.astype(np.float32)
X_test = X_test.astype(np.float32)
y_train_cat = to_categorical(y_train, num_classes=3)
y_test_cat = to_categorical(y_test, num_classes=3)

# Red para clasificación (se trata de la CNN2)
input_layer = Input(shape=(64, 64, 40, 1))
x = Conv3D(32, (3, 3, 3), padding='same')(input_layer)
x = BatchNormalization()(x)
x = Activation('relu')(x)
x = MaxPooling3D((2, 2, 2))(x)

x = Conv3D(64, (3, 3, 3), padding='same')(x)
x = BatchNormalization()(x)
x = Activation('relu')(x)
x = MaxPooling3D((2, 2, 2))(x)

x = GlobalAveragePooling3D()(x)
x = Dense(128, activation='relu')(x)
output_layer = Dense(3, activation='softmax')(x)

cnn_classifier = Model(inputs=input_layer, outputs=output_layer)
cnn_classifier.compile(optimizer=Adam(learning_rate=0.001),
                       loss='categorical_crossentropy',
                       metrics=['accuracy'])

# Entrenamiento
early_stop = EarlyStopping(patience=10, restore_best_weights=True)
cnn_classifier.fit(X_train, y_train_cat,
                   validation_data=(X_test, y_test_cat),
                   epochs=50,
                   batch_size=16,
                   callbacks=[early_stop],
                   verbose=2)

# Evaluación
y_pred_probs = cnn_classifier.predict(X_test)
y_pred = np.argmax(y_pred_probs, axis=1)
acc = accuracy_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred, average="weighted")
report = classification_report(y_test, y_pred, digits=4)

(acc, f1, report)

# Resultados clasificación MRIs con CNN2
import pandas as pd

data = {
    "Clase": ["AD", "CN", "FTD", "Global"],
    "Precision": [0.6053, 0.5385, 0.6000, 0.5810],
    "Recall": [0.9200, 0.3333, 0.4000, 0.5902],
    "F1-score": [0.7302, 0.4118, 0.4800, 0.5590],
    "Support": [25, 21, 15, 61]
}

tabla_metrica_clase = pd.DataFrame(data)

print("=== Métricas por clase para CNN2 ===")
print(tabla_metrica_clase.to_string(index=False))

"""- Tendencia hacia AD: el clasificador está muy ajustado para identificar AD (puede ser debido a la mayor cantidad de AD en los datos o por patrones más claros).

- Desbalance y superposición de clases: CN y FTD suelen cruzarse en el espacio latente que ha sido aprendido por el modelo, complicando su diferenciación precisa.

- Interpretación clínica: podríamos señalar que el modelo es eficaz para identificar AD, pero debe perfeccionarse en la diferenciación de casos sanos o FTD para prevenir falsos negativos

El rendimiento global de la clasificación directa de las imágenes de resonancia magnética con CNN2 no resulta satisfactorio, por lo que se obvia esta opción y se procede con los embeddings + tests cognitivos + variables demográficas.

# 6. INTERPRETACIÓN DEL MEJOR MODELO APLICADO AL BLOQUE C: Random Forest.
"""

import numpy as np
import pandas as pd
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score, f1_score, classification_report
from sklearn.preprocessing import StandardScaler
from imblearn.over_sampling import SMOTE

# 1. Normalización
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train_concat)
X_test_scaled = scaler.transform(X_test_concat)

# 2. Balanceo del conjunto de entrenamiento
smote = SMOTE(random_state=42)
X_train_balanced, y_train_balanced = smote.fit_resample(X_train_scaled, y_train)

# 3. Definición y entrenamiento del modelo
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train_balanced, y_train_balanced)

# 4. Evaluación
y_pred = rf_model.predict(X_test_scaled)
acc = accuracy_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred, average="weighted")

# 5. Resultados
print("\n=== Random Forest ===")
print(f"Accuracy: {acc:.4f}")
print(f"F1-score: {f1:.4f}")
print(classification_report(y_test, y_pred))

# 6. Tabla resumen
df_resultado = pd.DataFrame([{
    "Modelo": "Random Forest",
    "Accuracy": acc,
    "F1-score": f1
}])
print("\nResumen:")
print(df_resultado)

# Matriz de confusión
from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=['AD', 'CN', 'FTD'],
            yticklabels=['AD', 'CN', 'FTD'])
plt.xlabel('Predicho')
plt.ylabel('Real')
plt.title('Matriz de Confusión')
plt.show()

# Reporte clasificación por clase
from sklearn.metrics import classification_report
import pandas as pd

report = classification_report(y_test, y_pred, output_dict=True, target_names=['AD', 'CN', 'FTD'])
df_report = pd.DataFrame(report).transpose().drop('accuracy', errors='ignore')

df_report[['precision', 'recall', 'f1-score']].plot(kind='bar', figsize=(10, 6))
plt.title('Métricas por Clase')
plt.ylim(0, 1)
plt.legend(loc='lower right')
plt.show()

# Curvas ROC por clase
from sklearn.metrics import roc_curve, auc
from sklearn.preprocessing import label_binarize
from itertools import cycle

# Binarizamos las etiquetas
y_test_bin = label_binarize(y_test, classes=[0, 1, 2])
y_pred_prob = rf_model.predict_proba(X_test_scaled)

# Calculamos ROC para cada clase
fpr = dict()
tpr = dict()
roc_auc = dict()
n_classes = 3

for i in range(n_classes):
    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_pred_prob[:, i])
    roc_auc[i] = auc(fpr[i], tpr[i])

# Plot
plt.figure(figsize=(8, 6))
colors = cycle(['blue', 'red', 'green'])
for i, color in zip(range(n_classes), colors):
    plt.plot(fpr[i], tpr[i], color=color, lw=2,
             label=f'Clase {i} (AUC = {roc_auc[i]:.2f})')

plt.plot([0, 1], [0, 1], 'k--', lw=2)
plt.xlabel('Tasa de Falsos Positivos')
plt.ylabel('Tasa de Verdaderos Positivos')
plt.title('Curva ROC Multiclase')
plt.legend(loc='lower right')
plt.show()

# Importancia de variables
importances = rf_model.feature_importances_
indices = np.argsort(importances)[::-1]

# Nombres de características
feature_names = numerical_cols + list(preprocessor.named_transformers_['cat'].get_feature_names_out()) + \
                [f'embedding_{i}' for i in range(embeddings_cnn2_train.shape[1])]

plt.figure(figsize=(12, 8))
plt.title('Importancia de Variables')
plt.bar(range(30), importances[indices[:30]], align='center', color='skyblue')  # Top 20
plt.xticks(range(30), [feature_names[i] for i in indices[:30]], rotation=90)
plt.tight_layout()
plt.show()

# Distribución de errores
error_df = pd.DataFrame({
    'Real': y_test,
    'Predicho': y_pred,
    'Correcto': y_test == y_pred
})

sns.countplot(data=error_df, x='Real', hue='Correcto',
              palette={True: 'skyblue', False: 'red'})
plt.xticks([0, 1, 2], ['AD', 'CN', 'FTD'])
plt.title('Aciertos vs Errores por Clase')
plt.show()

# Análisis clases mal clasificadas
misclassified = error_df[error_df['Correcto'] == False]
sns.heatmap(pd.crosstab(misclassified['Real'], misclassified['Predicho']),
            annot=True, fmt='d', cmap='Reds')
plt.xlabel('Predicho')
plt.ylabel('Real')
plt.title('Errores entre Clases')
plt.show()

# Representación de mapas de calor con importancia de los embeddings
importances = rf_model.feature_importances_

# Los embeddings están al final de X_train_concat
embedding_importances = importances[-128:]  # 128 es el tamaño de los embeddings

# Gráfico de importancia de los embeddings
plt.figure(figsize=(12, 6))
plt.bar(range(128), embedding_importances, color='skyblue')
plt.xlabel('Dimensión del Embedding')
plt.ylabel('Importancia en el Modelo')
plt.title('Importancia de cada Dimensión del Embedding')
plt.show()

from tensorflow.keras.models import Model

dense_layer = cnn_model2.layers[-1]  # Capa Dense(128)
dense_weights = dense_layer.get_weights()[0]  # Pesos shape: (64, 128)

# Combinamos importancias de los embeddings con los pesos de la capa Dense
channel_importance = np.dot(dense_weights, embedding_importances)  # Shape: (64,)

# Diccionario para activaciones ponderadas por grupo
group_heatmaps = {0: np.zeros((32, 32, 20)),  # AD
                  1: np.zeros((32, 32, 20)),  # CN
                  2: np.zeros((32, 32, 20))}  # FTD

for i in range(len(X_train)):
    diagnosis = y_train[i]
    conv_act, _ = activation_model.predict(X_train[i:i+1])  # Shape: (1, 32, 32, 20, 64)
    conv_act = conv_act[0]  # Eliminamos batch_size

    # Multiplicamos cada canal por su importancia y sumamos
    weighted_act = np.sum(conv_act * channel_importance, axis=-1)  # Shape: (32, 32, 20)
    group_heatmaps[diagnosis] += weighted_act

# Promediamos
for diag in group_heatmaps:
    group_heatmaps[diag] /= np.sum(y_train == diag)

def upsample_heatmap(heatmap_3d, target_shape=(64, 64, 40)):
    zoom_factors = (
        target_shape[0] / heatmap_3d.shape[0],
        target_shape[1] / heatmap_3d.shape[1],
        target_shape[2] / heatmap_3d.shape[2]
    )
    return zoom(heatmap_3d, zoom_factors)

# Upsample para cada grupo
upsampled_heatmaps = {
    diag: upsample_heatmap(heatmap)
    for diag, heatmap in group_heatmaps.items()
}

#!pip install nilearn

from nilearn import plotting
from nilearn.image import new_img_like

# Asumimos que X_train[0] es una imagen nibabel con affine correcto
template_img = nib.Nifti1Image(X_train[0,...,0], affine=np.eye(4))

for diag, diag_name in zip([0, 1, 2], ['AD', 'CN', 'FTD']):
    heatmap_img = new_img_like(template_img, upsampled_heatmaps[diag])

    plotting.plot_stat_map(
        heatmap_img,
        bg_img=template_img,  # Fondo anatómico
        title=f'Mapa de Calor - {diag_name}',
        display_mode='ortho',
        cut_coords=(0, 0, 0),  # Centro del cerebro
        cmap='magma',
        threshold=np.percentile(upsampled_heatmaps[diag], 95)  # Top 5% de activación
    )
plt.show()

import plotly.graph_objects as go

# Crear malla 3D del heatmap (ejemplo para AD)
x, y, z = np.mgrid[:64, :64, :40]
heatmap_ad = upsampled_heatmaps[0]

fig = go.Figure(data=go.Volume(
    x=x.flatten(),
    y=y.flatten(),
    z=z.flatten(),
    value=heatmap_ad.flatten(),
    isomin=np.percentile(heatmap_ad, 95),
    isomax=heatmap_ad.max(),
    opacity=0.1,
    surface_count=20,
    colorscale='hot'
))
fig.show()

import plotly.graph_objects as go
import numpy as np

# Volumen base: imagen T1 promedio o el primer sujeto (normalizado)
brain_volume = X_train[0, ..., 0]  # Shape: (64, 64, 40)
brain_volume = (brain_volume - brain_volume.min()) / (brain_volume.max() - brain_volume.min())  # Normalizamos

# Volumen de activación para AD
heatmap_ad = upsampled_heatmaps[0]

# Coordenadas para ambos
x, y, z = np.mgrid[:64, :64, :40]

fig = go.Figure()

# 🔵 Capa 1: cerebro base (grisáceo o azul)
fig.add_trace(go.Volume(
    x=x.flatten(),
    y=y.flatten(),
    z=z.flatten(),
    value=brain_volume.flatten(),
    isomin=0.1,
    isomax=1.0,
    opacity=0.05,
    surface_count=15,
    colorscale='Blues',
    showscale=False
))

# 🔴 Capa 2: activación destacada (hot)
fig.add_trace(go.Volume(
    x=x.flatten(),
    y=y.flatten(),
    z=z.flatten(),
    value=heatmap_ad.flatten(),
    isomin=np.percentile(heatmap_ad, 95),
    isomax=heatmap_ad.max(),
    opacity=0.25,
    surface_count=8,
    colorscale='hot',
    showscale=True
))

fig.update_layout(
    title='Volumen cerebral con activaciones destacadas (Grad-CAM - AD)',
    scene=dict(
        xaxis_title='X',
        yaxis_title='Y',
        zaxis_title='Z',
        bgcolor='black'
    )
)

fig.show()

import plotly.graph_objects as go
import numpy as np

# Volumen base: imagen T1 promedio o el primer sujeto (normalizado)
brain_volume = X_train[0, ..., 0]  # Shape: (64, 64, 40)
brain_volume = (brain_volume - brain_volume.min()) / (brain_volume.max() - brain_volume.min())  # Normalizamos

# Volumen de activación para CN
heatmap_ad = upsampled_heatmaps[1]

# Coordenadas para ambos
x, y, z = np.mgrid[:64, :64, :40]

fig = go.Figure()

# 🔵 Capa 1: cerebro base (grisáceo o azul)
fig.add_trace(go.Volume(
    x=x.flatten(),
    y=y.flatten(),
    z=z.flatten(),
    value=brain_volume.flatten(),
    isomin=0.1,
    isomax=1.0,
    opacity=0.05,
    surface_count=15,
    colorscale='Blues',
    showscale=False
))

# 🔴 Capa 2: activación destacada (hot)
fig.add_trace(go.Volume(
    x=x.flatten(),
    y=y.flatten(),
    z=z.flatten(),
    value=heatmap_ad.flatten(),
    isomin=np.percentile(heatmap_ad, 95),
    isomax=heatmap_ad.max(),
    opacity=0.25,
    surface_count=8,
    colorscale='hot',
    showscale=True
))

fig.update_layout(
    title='Volumen cerebral con activaciones destacadas (Grad-CAM - CN)',
    scene=dict(
        xaxis_title='X',
        yaxis_title='Y',
        zaxis_title='Z',
        bgcolor='black'
    )
)

fig.show()

import plotly.graph_objects as go
import numpy as np

# Volumen base: imagen T1 promedio o el primer sujeto (normalizado)
brain_volume = X_train[0, ..., 0]  # Shape: (64, 64, 40)
brain_volume = (brain_volume - brain_volume.min()) / (brain_volume.max() - brain_volume.min())  # Normalizamos

# Volumen de activación para FTD
heatmap_ad = upsampled_heatmaps[2]

# Coordenadas para ambos
x, y, z = np.mgrid[:64, :64, :40]

fig = go.Figure()

# 🔵 Capa 1: cerebro base (grisáceo o azul)
fig.add_trace(go.Volume(
    x=x.flatten(),
    y=y.flatten(),
    z=z.flatten(),
    value=brain_volume.flatten(),
    isomin=0.1,
    isomax=1.0,
    opacity=0.05,
    surface_count=15,
    colorscale='Blues',
    showscale=False
))

# 🔴 Capa 2: activación destacada (hot)
fig.add_trace(go.Volume(
    x=x.flatten(),
    y=y.flatten(),
    z=z.flatten(),
    value=heatmap_ad.flatten(),
    isomin=np.percentile(heatmap_ad, 95),
    isomax=heatmap_ad.max(),
    opacity=0.25,
    surface_count=8,
    colorscale='hot',
    showscale=True
))

fig.update_layout(
    title='Volumen cerebral con activaciones destacadas (Grad-CAM - FTD)',
    scene=dict(
        xaxis_title='X',
        yaxis_title='Y',
        zaxis_title='Z',
        bgcolor='black'
    )
)

fig.show()

import matplotlib.pyplot as plt
import numpy as np

# Volumen anatómico base (T1 de un paciente)
brain_img = X_train[0, :, :, :, 0]  # (64, 64, 40)

# Mapa de calor correspondiente (por ejemplo, AD)
heatmap = upsampled_heatmaps[0]     # (64, 64, 40)

# Corte axial central
z = brain_img.shape[2] // 2
base_slice = brain_img[:, :, z]
heatmap_slice = heatmap[:, :, z]

# Normalizamos para mejorar contraste
base_slice_norm = (base_slice - base_slice.min()) / (np.ptp(base_slice))

# Visualización
plt.figure(figsize=(6, 6))
plt.imshow(base_slice_norm, cmap='gray', origin='lower')
plt.imshow(heatmap_slice, cmap='hot', alpha=0.5, origin='lower')
plt.title("Corte Axial con Zonas de Activación - Clase AD (0)")
plt.axis('off')
plt.colorbar(label="Activación Grad-CAM")
plt.show()

import matplotlib.pyplot as plt
import numpy as np

# Volumen anatómico base (T1 de un paciente)
brain_img = X_train[0, :, :, :, 0]  # (64, 64, 40)

# Mapa de calor correspondiente (por ejemplo, CN)
heatmap = upsampled_heatmaps[1]     # (64, 64, 40)

# Corte axial central
z = brain_img.shape[2] // 2
base_slice = brain_img[:, :, z]
heatmap_slice = heatmap[:, :, z]

# Normalizamos para mejorar contraste
base_slice_norm = (base_slice - base_slice.min()) / (np.ptp(base_slice))

# Visualización
plt.figure(figsize=(6, 6))
plt.imshow(base_slice_norm, cmap='gray', origin='lower')
plt.imshow(heatmap_slice, cmap='hot', alpha=0.5, origin='lower')
plt.title("Corte Axial con Zonas de Activación - Clase CN (1)")
plt.axis('off')
plt.colorbar(label="Activación Grad-CAM")
plt.show()

import matplotlib.pyplot as plt
import numpy as np

# Volumen anatómico base (T1 de un paciente)
brain_img = X_train[0, :, :, :, 0]  # (64, 64, 40)

# Mapa de calor correspondiente (por ejemplo, FTD)
heatmap = upsampled_heatmaps[2]     # (64, 64, 40)

# Corte axial central
z = brain_img.shape[2] // 2
base_slice = brain_img[:, :, z]
heatmap_slice = heatmap[:, :, z]

# Normalizamos para mejorar contraste
base_slice_norm = (base_slice - base_slice.min()) / (np.ptp(base_slice))

# Visualización
plt.figure(figsize=(6, 6))
plt.imshow(base_slice_norm, cmap='gray', origin='lower')
plt.imshow(heatmap_slice, cmap='hot', alpha=0.5, origin='lower')
plt.title("Corte Axial con Zonas de Activación - Clase FTD (2)")
plt.axis('off')
plt.colorbar(label="Activación Grad-CAM")
plt.show()

"""Los mapas de calor representan los cerebros de pacientes con distintos perfiles observados con una vista axial, es decir, superior. La interpretación de las imágenes resultantes con posibles biomarcadores es la siguiente:

**1. Clase 1 -- CN (Control Normal):**
- La activación es leve y dispersa, con pequeños focos en áreas periféricas, particularmente en el cerebelo y la corteza occipital.
- Este patrón indica que el modelo no detecta señales patológicas evidentes: se basa en la falta de atrofia o cambios estructurales significativos, lo que concuerda con un perfil saludable.
- Se trata de un patrón de activación más "neutral" y universal

**2. Clase 0 -- AD (Alzheimer):**
- La activación se enfoca en áreas más internas y bilaterales, particularmente en:
  - Lóbulos temporales mediales (región del hipocampo).
  - Parietal inferior y subcorticales.
- Estas áreas son biomarcadores tradicionales en AD: el modelo ha logrado identificarlas como rasgos del deterioro relacionado con el Alzheimer.
- Activación intensa y localizada, lo que sugiere una señal anatómica robusta

**3. Clase 2 -- FTD (Frontotemporal Dementia):**
- El patrón es bastante parecido al de AD, pero se puede distinguir por:
  - Mayor influencia en áreas frontales o laterales prefrontales.
  - Regiones más elevadas, lo que coincide con la atrofia frontotemporal característica de FTD.
- La activación es igualmente clara y precisa, aunque está más alejada en comparación con la de AD.

| Paciente | Clase real | Zonas activadas      | ¿Coincide con otros de su clase? |
| -------- | ---------- | -------------------- | ------------------------------- |
| ...        | CN         | Occipital + cerebelo | Parcialmente                    |
| ...      | AD         | Temporal medial      | Sí                              |
| ...      | FTD        | Frontal lateral      | Parcialmente, sobre todo frontal                              |
"""

import joblib

# Guardado del modelo
joblib.dump(rf_model, "/content/drive/MyDrive/TFG/rf_model.pkl")

print("✅ Modelo RF guardado como 'rf_model.pkl'")

import numpy as np

# Guardamos embeddings e IDs de entrenamiento
np.savez_compressed(
    "/content/drive/MyDrive/TFG/embeddings_cnn2_train.npz",
    embeddings=embeddings_cnn2_train,
    ids=train_ids
)

# Guardamos embeddings e IDs de test
np.savez_compressed(
    "/content/drive/MyDrive/TFG/embeddings_cnn2_test.npz",
    embeddings=embeddings_cnn2_test,
    ids=test_ids
)

print("¡Embeddings guardados correctamente!")
